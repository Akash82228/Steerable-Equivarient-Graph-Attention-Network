{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QM9 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation of necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.1.1.tar.gz (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m393.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[49 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/placeholder.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_csr.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_coo.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/utils.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/scatter.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/testing.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/std.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/logsumexp.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/softmax.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_scatter.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_scatter.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_scatter.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torch_scatter._scatter_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310/csrc\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/akashsharma/anaconda3/include -fPIC -O2 -isystem /Users/akashsharma/anaconda3/include -DWITH_PYTHON -Icsrc -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/TH -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/THC -I/Users/akashsharma/anaconda3/include/python3.10 -c csrc/cpu/scatter_cpu.cpp -o build/temp.macosx-11.1-arm64-cpython-310/csrc/cpu/scatter_cpu.o -O3 -Wno-sign-compare -arch arm64 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -DTORCH_EXTENSION_NAME=_scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=gnu++14\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/extension.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/python.h:12:\n",
      "  \u001b[31m   \u001b[0m /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/utils/pybind.h:7:10: fatal error: 'pybind11/pybind11.h' file not found\n",
      "  \u001b[31m   \u001b[0m #include <pybind11/pybind11.h>\n",
      "  \u001b[31m   \u001b[0m          ^~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m 1 error generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-scatter\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-scatter\n",
      "Failed to build torch-scatter\n",
      "Installing collected packages: torch-scatter\n",
      "  Running setup.py install for torch-scatter ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for torch-scatter\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[51 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /Users/akashsharma/anaconda3/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/placeholder.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_csr.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/segment_coo.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/utils.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/scatter.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/testing.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/std.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/logsumexp.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m copying torch_scatter/composite/softmax.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_scatter/composite\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_scatter.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_scatter.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_scatter.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_scatter.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_scatter.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torch_scatter._scatter_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310/csrc\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/akashsharma/anaconda3/include -fPIC -O2 -isystem /Users/akashsharma/anaconda3/include -DWITH_PYTHON -Icsrc -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/TH -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/THC -I/Users/akashsharma/anaconda3/include/python3.10 -c csrc/cpu/scatter_cpu.cpp -o build/temp.macosx-11.1-arm64-cpython-310/csrc/cpu/scatter_cpu.o -O3 -Wno-sign-compare -arch arm64 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -DTORCH_EXTENSION_NAME=_scatter_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=gnu++14\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/scatter_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/extension.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/python.h:12:\n",
      "  \u001b[31m   \u001b[0m /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/utils/pybind.h:7:10: fatal error: 'pybind11/pybind11.h' file not found\n",
      "  \u001b[31m   \u001b[0m #include <pybind11/pybind11.h>\n",
      "  \u001b[31m   \u001b[0m          ^~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m 1 error generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m torch-scatter\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n",
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
      "Collecting torch-sparse\n",
      "  Downloading torch_sparse-0.6.17.tar.gz (209 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from torch-sparse) (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from scipy->torch-sparse) (1.23.5)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[80 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/matmul.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/permute.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/add.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/reduce.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/narrow.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/masked_select.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/cat.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/eye.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/convert.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/coalesce.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/tensor.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/bandwidth.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/mul.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/transpose.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/utils.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/diag.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/rw.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/storage.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/sample.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spspmm.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/index_select.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/saint.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/select.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/typing.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spadd.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/testing.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spmm.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/metis.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_sparse.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_sparse.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_sparse.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/css'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/html'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/tests'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/examples'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/benchmark'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'benchmark'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._relabel_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310/csrc\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/akashsharma/anaconda3/include -fPIC -O2 -isystem /Users/akashsharma/anaconda3/include -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/TH -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/THC -I/Users/akashsharma/anaconda3/include/python3.10 -c csrc/cpu/relabel_cpu.cpp -o build/temp.macosx-11.1-arm64-cpython-310/csrc/cpu/relabel_cpu.o -O3 -Wno-sign-compare -D_LIBCPP_DISABLE_AVAILABILITY -arch arm64 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -DTORCH_EXTENSION_NAME=_relabel_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=gnu++14\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/relabel_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/relabel_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/extension.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/python.h:12:\n",
      "  \u001b[31m   \u001b[0m /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/utils/pybind.h:7:10: fatal error: 'pybind11/pybind11.h' file not found\n",
      "  \u001b[31m   \u001b[0m #include <pybind11/pybind11.h>\n",
      "  \u001b[31m   \u001b[0m          ^~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m 1 error generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for torch-sparse\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for torch-sparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build torch-sparse\n",
      "Installing collected packages: torch-sparse\n",
      "  Running setup.py install for torch-sparse ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for torch-sparse\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[82 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m Compiling without OpenMP...\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /Users/akashsharma/anaconda3/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/matmul.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/permute.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/add.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/reduce.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/narrow.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/masked_select.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/cat.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/eye.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/convert.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/coalesce.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/__init__.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/tensor.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/bandwidth.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/mul.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/transpose.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/utils.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/diag.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/rw.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/storage.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/sample.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spspmm.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/index_select.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/saint.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/select.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/typing.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spadd.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/testing.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/spmm.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m copying torch_sparse/metis.py -> build/lib.macosx-11.1-arm64-cpython-310/torch_sparse\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing torch_sparse.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to torch_sparse.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to torch_sparse.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to torch_sparse.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/css'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/html'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/tests'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/examples'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'third_party/parallel-hashmap/benchmark'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'test'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*' found under directory 'benchmark'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'torch_sparse.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'torch_sparse._relabel_cpu' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310/csrc\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-310/csrc/cpu\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/akashsharma/anaconda3/include -fPIC -O2 -isystem /Users/akashsharma/anaconda3/include -DWITH_PYTHON -Icsrc -Ithird_party/parallel-hashmap -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/TH -I/Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/THC -I/Users/akashsharma/anaconda3/include/python3.10 -c csrc/cpu/relabel_cpu.cpp -o build/temp.macosx-11.1-arm64-cpython-310/csrc/cpu/relabel_cpu.o -O3 -Wno-sign-compare -D_LIBCPP_DISABLE_AVAILABILITY -arch arm64 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -DTORCH_EXTENSION_NAME=_relabel_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=gnu++14\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/relabel_cpu.cpp:1:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/relabel_cpu.h:3:\n",
      "  \u001b[31m   \u001b[0m In file included from csrc/cpu/../extensions.h:2:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/torch.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/extension.h:6:\n",
      "  \u001b[31m   \u001b[0m In file included from /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/python.h:12:\n",
      "  \u001b[31m   \u001b[0m /Users/akashsharma/anaconda3/lib/python3.10/site-packages/torch/include/torch/csrc/utils/pybind.h:7:10: fatal error: 'pybind11/pybind11.h' file not found\n",
      "  \u001b[31m   \u001b[0m #include <pybind11/pybind11.h>\n",
      "  \u001b[31m   \u001b[0m          ^~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m 1 error generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m torch-sparse\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from torch-geometric) (2.28.1)\n",
      "Requirement already satisfied: jinja2 in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from torch-geometric) (3.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from torch-geometric) (4.64.1)\n",
      "Requirement already satisfied: pyparsing in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from torch-geometric) (3.0.9)\n",
      "Requirement already satisfied: numpy in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from torch-geometric) (1.23.5)\n",
      "Requirement already satisfied: scipy in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from torch-geometric) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from torch-geometric) (1.2.1)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from jinja2->torch-geometric) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from requests->torch-geometric) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from requests->torch-geometric) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from requests->torch-geometric) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/akashsharma/anaconda3/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.1.1)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910459 sha256=7b109e6b0b72932fc00a9604e080ca516351e0750f502082cabe8085952e7c06\n",
      "  Stored in directory: /Users/akashsharma/Library/Caches/pip/wheels/aa/16/a8/fd7737d723cc1eb8df023c016c262ff4520091e1b022f8c164\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=f32237b208bba7b0ad9e9c71c6b11d2f67c6ee459403666a8282b7d869bfee2c\n",
      "  Stored in directory: /Users/akashsharma/Library/Caches/pip/wheels/46/78/0e/8e5e2b500f83a682c8d7e7ce820638cf99faa894a662f71cf0\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install torch geometric\n",
    "%pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
    "%pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
    "%pip install torch-geometric\n",
    "%pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
    "%pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download QM9 dataset\n",
    "\n",
    "make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Callable, List\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.data import (InMemoryDataset, download_url, extract_zip,\n",
    "                                  Data)\n",
    "from torch_geometric.nn import radius_graph\n",
    "from e3nn.o3 import Irreps, spherical_harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAR2EV = 27.211386246\n",
    "KCALMOL2EV = 0.04336414\n",
    "\n",
    "conversion = torch.tensor([\n",
    "    1., 1., HAR2EV, HAR2EV, HAR2EV, 1., HAR2EV, HAR2EV, HAR2EV, HAR2EV, HAR2EV,\n",
    "    1., KCALMOL2EV, KCALMOL2EV, KCALMOL2EV, KCALMOL2EV, 1., 1., 1.\n",
    "])\n",
    "\n",
    "atomrefs = {\n",
    "    6: [0., 0., 0., 0., 0.],\n",
    "    7: [\n",
    "        -13.61312172, -1029.86312267, -1485.30251237, -2042.61123593,\n",
    "        -2713.48485589\n",
    "    ],\n",
    "    8: [\n",
    "        -13.5745904, -1029.82456413, -1485.26398105, -2042.5727046,\n",
    "        -2713.44632457\n",
    "    ],\n",
    "    9: [\n",
    "        -13.54887564, -1029.79887659, -1485.2382935, -2042.54701705,\n",
    "        -2713.42063702\n",
    "    ],\n",
    "    10: [\n",
    "        -13.90303183, -1030.25891228, -1485.71166277, -2043.01812778,\n",
    "        -2713.88796536\n",
    "    ],\n",
    "    11: [0., 0., 0., 0., 0.],\n",
    "}\n",
    "\n",
    "\n",
    "targets = ['mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'U0',\n",
    "           'U', 'H', 'G', 'Cv', 'U0_atom', 'U_atom', 'H_atom', 'G_atom', 'A', 'B', 'C']\n",
    "\n",
    "tid = targets.index(\"alpha\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =1000\n",
    "batch_size=128\n",
    "lr = 5e-4 #learning rate\n",
    "weight_decay=1e-8\n",
    "num_workers =4 #num workers in dataloader\n",
    "save_dir = \"saved models\" #directory to save models\n",
    "\n",
    "#set the task variable\n",
    "task=\"graph\"\n",
    "\n",
    "#set the logging flag\n",
    "log = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"qm9\"\n",
    "root = \"datasets\" #dataset location\n",
    "target = \"alpha\" \n",
    "radius = 2 #Radius (Angstrom) between which atoms to add links.\n",
    "feature_type = \"one_hot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =\"segnn\"\n",
    "hidden_features= 128 #number of hidden features\n",
    "lmax_h =2 #max degree of hidden rep\n",
    "lmax_attr=3 #max degree of geometric attribute embedding\n",
    "subspace_type = \"weightbalanced\" #how to divide spherical harmonic subspace\n",
    "layers = 7 #number of message passing layers\n",
    "norm = \"instance\" #normalisation type\n",
    "pool = \"avg\"\n",
    "conv_type = \"linear\" #linear or non-linear aggregation of local information in SEConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetGetter(object):\n",
    "    \"\"\" Gets relevant target \"\"\"\n",
    "\n",
    "    def __init__(self, target):\n",
    "        self.target = target\n",
    "        self.target_idx = targets.index(target)\n",
    "\n",
    "    def __call__(self, data):\n",
    "        # Specify target.\n",
    "        data.y = data.y[0, self.target_idx]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QM9(InMemoryDataset):\n",
    "    \n",
    "    r\"\"\"The QM9 dataset from the `\"MoleculeNet: A Benchmark for Molecular\n",
    "    Machine Learning\" <https://arxiv.org/abs/1703.00564>`_ paper, consisting of\n",
    "    about 130,000 molecules with 19 regression targets.\n",
    "    Each molecule includes complete spatial information for the single low\n",
    "    energy conformation of the atoms in the molecule.\n",
    "    In addition, we provide the atom features from the `\"Neural Message\n",
    "    Passing for Quantum Chemistry\" <https://arxiv.org/abs/1704.01212>`_ paper. \"\"\"\n",
    "\n",
    "    raw_url = ('https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/'\n",
    "               'molnet_publish/qm9.zip')\n",
    "    raw_url2 = 'https://ndownloader.figshare.com/files/3195404'\n",
    "    processed_url = 'https://data.pyg.org/datasets/qm9_v3.zip'\n",
    "\n",
    "    def __init__(self, root, target, radius, partition, lmax_attr, feature_type):\n",
    "        # assert feature_type in [\"one_hot\", \"cormorant\", \"gilmer\"], \"Please use valid features\"\n",
    "        # assert target in targets\n",
    "        # assert partition in [\"train\", \"valid\", \"test\"]\n",
    "        self.root = osp.abspath(osp.join(root, \"qm9\"))\n",
    "        self.target = target\n",
    "        self.radius = radius\n",
    "        self.partition = partition\n",
    "        self.feature_type = feature_type\n",
    "        self.lmax_attr = lmax_attr\n",
    "        self.attr_irreps = Irreps.spherical_harmonics(lmax_attr)\n",
    "        transform = TargetGetter(self.target)\n",
    "\n",
    "        super().__init__(self.root, transform)\n",
    "\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    def calc_stats(self):\n",
    "        ys = np.array([data.y.item() for data in self])\n",
    "        mean = np.mean(ys)\n",
    "        mad = np.mean(np.abs(ys - mean))\n",
    "        return mean, mad\n",
    "\n",
    "    def atomref(self, target) -> Optional[torch.Tensor]:\n",
    "        if target in atomrefs:\n",
    "            out = torch.zeros(100)\n",
    "            out[torch.tensor([1, 6, 7, 8, 9])] = torch.tensor(atomrefs[target])\n",
    "            return out.view(-1, 1)\n",
    "        return None\n",
    "    \n",
    "    @ property\n",
    "    def raw_file_names(self) -> List[str]:\n",
    "        try:\n",
    "            import rdkit  # noqa\n",
    "            return ['gdb9.sdf', 'gdb9.sdf.csv', 'uncharacterized.txt']\n",
    "        except ImportError:\n",
    "            print(\"Please install rdkit\")\n",
    "            return\n",
    "        \n",
    "    @ property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return [\"_\".join([self.partition, \"r=\"+str(np.round(self.radius, 2)),\n",
    "                          self.feature_type, \"l=\"+str(self.lmax_attr)]) + '.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        print(\"Downloading to\", self.raw_dir, self.raw_url)\n",
    "        try:\n",
    "            import rdkit  # noqa\n",
    "            file_path = download_url(self.raw_url, self.raw_dir)\n",
    "            extract_zip(file_path, self.raw_dir)\n",
    "            os.unlink(file_path)\n",
    "\n",
    "            file_path = download_url(self.raw_url2, self.raw_dir)\n",
    "            os.rename(osp.join(self.raw_dir, '3195404'),\n",
    "                      osp.join(self.raw_dir, 'uncharacterized.txt'))\n",
    "        except ImportError:\n",
    "            path = download_url(self.processed_url, self.raw_dir)\n",
    "            extract_zip(path, self.raw_dir)\n",
    "            os.unlink(path)\n",
    "\n",
    "    '''This code defines the process() method of a PyTorch dataset class. \n",
    "    The purpose of this method is to process the raw data of the dataset into a format \n",
    "    that can be used for training a machine learning model.'''\n",
    "\n",
    "    def process(self):\n",
    "        try:\n",
    "            import rdkit\n",
    "            from rdkit import Chem\n",
    "            from rdkit.Chem.rdchem import HybridizationType\n",
    "            from rdkit.Chem.rdchem import BondType as BT\n",
    "            from rdkit import RDLogger\n",
    "            RDLogger.DisableLog('rdApp.*')\n",
    "        except ImportError:\n",
    "            print(\"Please install rdkit\")\n",
    "            return\n",
    "\n",
    "        print(\"Processing data for\", self.partition, \"set with radius=\" + str(np.round(self.radius, 2)) +\n",
    "              \",\", \"l_attr=\" + str(self.lmax_attr), \"and\", self.feature_type, \"features.\")\n",
    "        types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\n",
    "\n",
    "        with open(self.raw_paths[1], 'r') as f:\n",
    "            target = f.read().split('\\n')[1:-1]\n",
    "            target = [[float(x) for x in line.split(',')[1:20]]\n",
    "                      for line in target]\n",
    "            target = torch.tensor(target, dtype=torch.float)\n",
    "            target = torch.cat([target[:, 3:], target[:, :3]], dim=-1)\n",
    "            target = target * conversion.view(1, -1)\n",
    "\n",
    "        with open(self.raw_paths[2], 'r') as f:\n",
    "            skip = [int(x.split()[0]) - 1 for x in f.read().split('\\n')[9:-2]]\n",
    "\n",
    "        suppl = Chem.SDMolSupplier(self.raw_paths[0], removeHs=False,\n",
    "                                   sanitize=False)\n",
    "        data_list = []\n",
    "\n",
    "        # Create splits \n",
    "        Nmols = len(suppl) - len(skip)\n",
    "        Ntrain = 10000\n",
    "        Ntest = int(0.5*Nmols)\n",
    "        # Nvalid = Nmols - (Ntrain + Ntest)\n",
    "        Nvalid = 1000\n",
    "\n",
    "\n",
    "\n",
    "        # sets the random seed to a specific value (0), \n",
    "        # so that the same random permutation is generated every time the code is run.\n",
    "        np.random.seed(0) \n",
    "        data_perm = np.random.permutation(Nmols)\n",
    "        train, valid, test = np.split(data_perm, [Ntrain, Ntrain+Nvalid])\n",
    "        indices = {\"train\": train, \"valid\": valid, \"test\": test}\n",
    "\n",
    "        # Add a very ugly second index to align with Cormorant splits.\n",
    "        j = 0\n",
    "        for i, mol in enumerate(tqdm(suppl)):\n",
    "            if i in skip:\n",
    "                continue\n",
    "            if j not in indices[self.partition]:\n",
    "                j += 1\n",
    "                continue\n",
    "            j += 1\n",
    "\n",
    "            N = mol.GetNumAtoms()\n",
    "\n",
    "            pos = suppl.GetItemText(i).split('\\n')[4:4 + N]\n",
    "            pos = [[float(x) for x in line.split()[:3]] for line in pos]\n",
    "            pos = torch.tensor(pos, dtype=torch.float)\n",
    "\n",
    "            edge_index = radius_graph(pos, r=self.radius, loop=False)\n",
    "\n",
    "            type_idx = []\n",
    "            atomic_number = []\n",
    "            aromatic = []\n",
    "            sp = []\n",
    "            sp2 = []\n",
    "            sp3 = []\n",
    "            num_hs = []\n",
    "            for atom in mol.GetAtoms():\n",
    "                type_idx.append(types[atom.GetSymbol()])\n",
    "                atomic_number.append(atom.GetAtomicNum())\n",
    "                aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
    "                hybridization = atom.GetHybridization()\n",
    "                sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
    "                sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
    "                sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
    "\n",
    "            z = torch.tensor(atomic_number, dtype=torch.long)\n",
    "\n",
    "            x = F.one_hot(torch.tensor(type_idx), num_classes=len(types)).float()\n",
    "\n",
    "            y = target[i].unsqueeze(0)\n",
    "            name = mol.GetProp('_Name')\n",
    "\n",
    "            edge_attr, node_attr, edge_dist = self.get_O3_attr(edge_index, pos, self.attr_irreps)\n",
    "\n",
    "            data = Data(x=x, pos=pos, edge_index=edge_index, edge_attr=edge_attr,\n",
    "                        node_attr=node_attr, additional_message_features=edge_dist, y=y, name=name, index=i)\n",
    "            data_list.append(data)\n",
    "\n",
    "        torch.save(self.collate(data_list), self.processed_paths[0])\n",
    "\n",
    "    def get_O3_attr(self, edge_index, pos, attr_irreps):\n",
    "        \"\"\" Creates spherical harmonic edge attributes and node attributes for the SEGNN \"\"\"\n",
    "        rel_pos = pos[edge_index[0]] - pos[edge_index[1]]  # pos_j - pos_i (note in edge_index stores tuples like (j,i))\n",
    "        edge_dist = rel_pos.pow(2).sum(-1, keepdims=True)\n",
    "        edge_attr = spherical_harmonics(attr_irreps, rel_pos, normalize=True,\n",
    "                                        normalization='component')  # Unnormalised for now\n",
    "        node_attr = scatter(edge_attr, edge_index[1], dim=0, reduce=\"mean\")\n",
    "        return edge_attr, node_attr, edge_dist\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'ellipsis' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     26\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m QM9(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m6\u001b[39m, feature_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone_hot\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m     ys \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[1;32m     31\u001b[0m     mean, mad \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcalc_stats()\n",
      "Cell \u001b[0;32mIn[27], line 13\u001b[0m, in \u001b[0;36mQM9.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Return the length of the dataset\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'ellipsis' has no len()"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = QM9(\"datasets\", \"alpha\", 2.0, \"train\", 6, feature_type=\"one_hot\")\n",
    "    print(\"length\", len(dataset))\n",
    "    ys = np.array([data.y.item() for data in dataset])\n",
    "    mean, mad = dataset.calc_stats()\n",
    "\n",
    "    for item in dataset:\n",
    "        print(item.edge_index)\n",
    "        break\n",
    "\n",
    "    print(\"mean\", mean, \"mad\", mad)\n",
    "\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     plt.subplot(121)\n",
    "#     plt.title(dataset.target)\n",
    "#     plt.hist(ys)\n",
    "#     plt.subplot(122)\n",
    "#     plt.title(dataset.target + \" standardised\")\n",
    "#     plt.hist((ys - mean)/mad)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qm9\n"
     ]
    }
   ],
   "source": [
    "dataset\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data(x=[5, 5], edge_index=[2, 20], edge_attr=[20, 49], y=13.210000038146973, pos=[5, 3], node_attr=[5, 49], additional_message_features=[20, 1], name='gdb_1', index=[1])\n",
      "===============================================================================================================\n",
      "Number of nodes: 5\n",
      "Number of edges: 20\n",
      "Average node degree: 4.00\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('===============================================================================================================')\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "# print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "# print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.3f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import Sampler\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(dataset, batch_size, num_workers, world_size = None, rank=None, train=True):\n",
    "    \"\"\" Create (disributed) dataloader \"\"\"\n",
    "\n",
    "    if world_size is not None and world_size > 1:\n",
    "        if train:\n",
    "            sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n",
    "        else:\n",
    "            sampler = DistributedEvalSampler(dataset, num_replicas=world_size, rank=rank)\n",
    "\n",
    "        parallel_batch_size = int(batch_size/world_size)\n",
    "        dataloader = DataLoader(dataset, batch_size=parallel_batch_size, shuffle=(sampler is None),\n",
    "                                sampler=sampler, num_workers=num_workers)\n",
    "    else:\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=train, num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for train set with radius=2, l_attr=3 and one_hot features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133885/133885 [03:52<00:00, 576.26it/s]\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 100000\n",
      "tensor([[1, 2, 3, 4, 0, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 4, 0, 1, 2, 3],\n",
      "        [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]])\n",
      "mean 75.26605450292587 mad 6.288199328145316\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAa90lEQVR4nO3df5TV9X3n8edLSIhRUVGYHcCIqVgRkqCMaE5c14QQSeKiRiWYpOKGlDY1m3iSbYt1t9ZuTSYpqT/ORlvaZCWmFanZFI4/iIp1bTgqwRXDD0OYBKoTJsMY/IE2WsD3/vF9j9653Lnzg5m5w8zrcc4993vf9/vj873zubzu9yeKCMzMzA6rdQPMzGxwcCCYmRngQDAzs+RAMDMzwIFgZmbJgWBmZoADYUiQdKWkH/X1uDa0Dcd+I2mHpA/34fxC0sk5/NeS/kdfzTvneZ6k5r6cZzUjB2pBZmZdkRTA5IhoqnVbeioifr/WbThY3kIwM+uCpGHx49mBcAiRtFjSzyXtkbRF0sWdjBeSvijpF5Kel/SXkg4rG2eJpBckbZf00ZL6f5H0TC7jF5J+r7/Xy/pPd/tMjjsg/UbSyZL+r6SXcjl3Zf3RHOVpSa9I+qSkYyXdI6ktl3uPpIkl83pE0v+UtDaX/YCk40ve/x1J/yrp15KuLWvHTEmPSXpRUouk/yXp7WWfx1WStgHbsvaHOe5OSZ8tm9/tkv4ih4/Ptr4oabekf2n/LCWNl/T9XKftkr5YMo/Dcz4vSNoCnNnZ59gvIsKPQ+QBXAaMpwjyTwKvAvXAlcCPSsYL4J+BMcC7gJ8Bn8v3rgT2Ar8LjAA+D+wElO9/HPgtQMB/Av4NOKPW6+5H3/aZkr4w4P0GuBO4Ntv0DuCcsjacXPL6OOAS4J3AUcA/Av9U8v4jwM+BU4DD83Vjvnca8ApwLjAK+CtgH/DhfH8GcDbFrvNJwDPA1WVteTA/j8OBOUArMA04AviH0vYCtwN/kcNfA/4aeFs+/mN+NocBTwJ/CrwdeDfwC+D8nK4R+Jdc5gnAJqB5wPpLrTusHwfxx4MNwIWdfLHnlLz+A2BNDl8JNJW8984c/z90sox/Ar5U63X1o2/7TElfGPB+A3wXWApMrPBeh0Co8P504IWS148A/72szatz+E+B5SXvHQH8e3sgVJj31cAPytryoZLX3yHDJl+fUiUQ/hxYWb4uwFnAs2W1a4D/ncO/KPsbLBrIQPAuo0OIpCskbcjN0Bcpfqkc38noz5UM/yvFr8R2v2ofiIh/y8EjcxkflfR4bua+CHysyjJskOthn4GB6Td/RPFreZ2kzeW7Xsra/05Jf5O7fV4GHgWOkTSiUrsotkyOzOHxpesTEa8Cvy6Z9ym5W+dXOe+vVmhz6ecxngM/n878JdAEPJC70BZn/URgfPvfIz+rPwHqerGMPudAOERIOhH4W+ALwHERcQzF5qQ6meSEkuF3UWzed7WMUcD3gSVAXS7jvirLsEGsF30GBqDfRMSvIuJ3I2I88HvArcpTNyv4CvDbwFkRMZpi9w9drEO7FkrWR9I7KXZBtbsN+CnFWU2jKf5hLp9v6e2gO8yP4vOpKCL2RMRXIuLdwH8GvixpFsU/9tsj4piSx1ER8bGeLqM/OBAOHUdQdM42KA7iUfza68wf5gG5E4AvAXd1Yxlvp9jX2gbsy4OGHzmoVlst9bTPwAD0G0mXlRwYfiHbuD9ft1LsV293FPAb4EVJY4DrutGedncDF0g6Jw8W/zkd/807CngZeEXSqRTHRapZAVwp6bQMl07bIumCPHiuXMb+fKwDXpb0x3kAeYSkaZLaDx6vAK7Jv8FE4L/2YH0PmgPhEBERW4BvAo9RfGneA6ytMslKioNXG4B7gW93Yxl7gC9SdMoXgE8Bqw6m3VY7vegzMDD95kzgCUmv5Hhfiojt+d6fActyd8o84CaKA7rPA48Dq7tqT0m7NgNXURz8bcm2lV7k9d+yrXsotqSqhl9E3J/teZhid9DDVUafDDxEcVD7MeDWiHgkIvZTbDFMB7bnev0dcHROdz3FbqLtwAPAHd1Z177SfoaADSE6hC/usdpxvzFvIZiZGeBAMDOz5F1GZmYGdHMLQcUdAjfm+czrszZG0oOStuXzsSXjXyOpSdJWSeeX1GfkfJok3ZJH4JE0StJdWX9C0qQ+Xk+zity3zd7SrS0ESTuAhoh4vqT2DWB3RDTmRRfHRsQfSzqN4tL0mRQXWTwEnBIR+yWtoziV7XGK85RviYj7Jf0B8N6I+H1J84GLI+KT1dp0/PHHx6RJk3qxymZv2bhxI1OmTGHkyLfuXdbc3Exra+urEXGk+7YNNU8++eTzETG24pvduZwZ2AEcX1bbylv3RKkHtpZchn1NyXg/BN6f4/y0pH458Del4+TwSIpTsVStTTNmzAizg3XiiSdGW1tbh9opp5wSwNPhvm1DELA+DvLWFUFxCfaTkhZlrS4iWjJUWoBxWZ9Ax0uvm7M2gY7nALfXO0wTEfuAl+h4RaFZv5DERz7yEWbMmMHSpUsBaG1theJGbu7bNqx09x7fH4iInZLGAQ9K+mmVcStdUh5V6tWm6TjjIowWAbzrXQN6RbcNUWvXrmX8+PHs2rWL2bNnc+qpp1Yb3X3bhrRubSFExM583gX8gGIfaqukeoB83pWjN9PxXhwTKe6H0pzD5fUO06j4jyiOBnZXaMfSiGiIiIaxYyvvAjPrifHji3u3jRs3josvvph169ZRV1cHxS2L3bdtWOkyECQdIemo9mGKe5RsorjkfEGOtoDikneyPj/PrjiJ4hLudbnpvUfS2XkGxhVl07TP61Lg4dzXZdZvXn31Vfbs2fPm8AMPPMC0adOYO3cuvLVbx33bho3u7DKqA36QZ9GNBP4hIlZL+jGwQtJC4FmK/4iDiNgsaQWwheI/o7gqivt3QHHzqNsp7k1yfz6guF/KHZKaKH49ze+DdTOrqrW1lYsvLv4DsX379vGpT32KOXPmcOaZZ7JkyZLRKv6nLPdtGzYO2QvTGhoaYv369bVuhg1Rkp6MiIZaLNt92/pTtb7tW1eYmRngQDAzs+RAMDMzoPvXIdggMWnxvb2abkfjx/u4JWZ9y3279ryFYGZmgAPBzMySA8HMzAAHgpmZJQeCmZkBDgQzM0sOBDMzAxwIZmaWHAhmZgY4EMzMLDkQzMwMcCCYmVlyIJiZGeBAMDOz5EAwMzPAgWBmZsmBYGZmgAPBzMySA8HMzAAHgpmZJQeCmZkBDgQzM0sOBDMzA2BkrRtgA2PS4nt7Nd2Oxo/3cUvM+pb7dt/xFoKZmQEOBDMzSw4EMzMDHAhmZpYcCGZmBjgQzMwsORDMzAzoQSBIGiHpKUn35Osxkh6UtC2fjy0Z9xpJTZK2Sjq/pD5D0sZ87xZJyvooSXdl/QlJk/pwHc06tX//fk4//XQuuOACAHbv3s3s2bMBprlf23DTky2ELwHPlLxeDKyJiMnAmnyNpNOA+cBUYA5wq6QROc1twCJgcj7mZH0h8EJEnAzcCHy9V2tj1kM333wzU6ZMefN1Y2Mjs2bNAtiE+7UNM90KBEkTgY8Df1dSvhBYlsPLgItK6ssj4vWI2A40ATMl1QOjI+KxiAjgu2XTtM/rbmBW+68ss/7S3NzMvffey+c+97k3aytXrmTBggXtL92vbVjp7hbCTcAfAW+U1OoiogUgn8dlfQLwXMl4zVmbkMPl9Q7TRMQ+4CXguPJGSFokab2k9W1tbd1sulllV199Nd/4xjc47LC3vgatra3U19cDA9evwX3bBocuA0HSBcCuiHiym/Os9AsoqtSrTdOxELE0IhoiomHs2LHdbI7Zge655x7GjRvHjBkzujtJv/VrcN+2waE7N7f7ADBX0seAdwCjJX0PaJVUHxEtudm8K8dvBk4omX4isDPrEyvUS6dpljQSOBrY3ct1MuvS2rVrWbVqFffddx+vvfYaL7/8Mp/5zGeoq6ujpaUFAPdrG2663EKIiGsiYmJETKI4qPZwRHwGWAW072xdAKzM4VXA/DzD4iSKg2zrcvN7j6Szcz/qFWXTtM/r0lxGxV9SZn3ha1/7Gs3NzezYsYPly5fzoQ99iO9973vMnTuXZcvad/u7X9vwcjC3v24EVkhaCDwLXAYQEZslrQC2APuAqyJif07zeeB24HDg/nwAfBu4Q1ITxS+o+QfRLrNeW7x4MfPmzQOYRrHP3/3ahg0dqj9YGhoaYv369bVuxoDr7b3fe2u43jNe0pMR0VCLZbtvDwz37QP5SmUzMwMcCGZmlhwIZmYGOBDMzCw5EMzMDHAgmJlZciCYmRngQDAzs+RAMDMzwIFgZmbJgWBmZoADwczMkgPBzMwAB4KZmSUHgpmZAQ4EMzNLDgQzMwMcCGZmlhwIZmYGOBDMzCw5EMzMDHAgmJlZciCYmRngQDAzs+RAMDMzwIFgZmbJgWBmZoADwczMkgPBzMwAB4KZmSUHgpmZAQ4EMzNLDgQzMwMcCGZmlroMBEnvkLRO0tOSNku6PutjJD0oaVs+H1syzTWSmiRtlXR+SX2GpI353i2SlPVRku7K+hOSJvXDupp18NprrzFz5kze9773MXXqVK677joAdu/eDTDZfduGm+5sIbwOfCgi3gdMB+ZIOhtYDKyJiMnAmnyNpNOA+cBUYA5wq6QROa/bgEXA5HzMyfpC4IWIOBm4Efj6wa+aWXWjRo3i4Ycf5umnn2bDhg2sXr2axx9/nMbGRoA97ts23HQZCFF4JV++LR8BXAgsy/oy4KIcvhBYHhGvR8R2oAmYKakeGB0Rj0VEAN8tm6Z9XncDs9p/YZn1F0kceeSRAOzdu5e9e/ciiZUrVwL8Okdz37Zho1vHECSNkLQB2AU8GBFPAHUR0QKQz+Ny9AnAcyWTN2dtQg6X1ztMExH7gJeA4yq0Y5Gk9ZLWt7W1dWsFzarZv38/06dPZ9y4ccyePZuzzjqL1tZWgL3gvm3DS7cCISL2R8R0YCLFL6JpVUav9OsnqtSrTVPejqUR0RARDWPHju2i1WZdGzFiBBs2bKC5uZl169axadOmaqO7b9uQ1qOzjCLiReARiv2jrbmpTD7vytGagRNKJpsI7Mz6xAr1DtNIGgkcDezuSdvMDsYxxxzDeeedx+rVq6mrq4Ni16j7tg0r3TnLaKykY3L4cODDwE+BVcCCHG0BsDKHVwHz8+yKkygOsK3LTe89ks7OfahXlE3TPq9LgYdzX6xZv2lra+PFF18E4De/+Q0PPfQQp556KnPnzoW3duu4b9uwMbIb49QDy/JsisOAFRFxj6THgBWSFgLPApcBRMRmSSuALcA+4KqI2J/z+jxwO3A4cH8+AL4N3CGpieLX0/y+WDmzalpaWliwYAH79+/njTfeYN68eVxwwQW8//3vZ8mSJaMlbcN924aRLgMhIn4CnF6h/mtgVifT3ADcUKG+Hjjg+ENEvEZ+6cwGynvf+16eeuqpA+rHHXccwM8ioqH8PfdtG8p8pbKZmQEOBDMzSw4EMzMDHAhmZpYcCGZmBjgQzMwsORDMzAxwIJiZWXIgmJkZ4EAwM7PkQDAzM8CBYGZmyYFgZmaAA8HMzJIDwczMAAeCmZklB4KZmQEOBDMzSw4EMzMDHAhmZpYcCGZmBjgQzMwsORDMzAxwIJiZWXIgmJkZ4EAwM7PkQDAzM8CBYGZmyYFgZmaAA8HMzJIDwczMAAeCmZklB4KZmQEOBDMzS10GgqQTJP2zpGckbZb0payPkfSgpG35fGzJNNdIapK0VdL5JfUZkjbme7dIUtZHSbor609ImtQP62rWwXPPPccHP/hBpkyZwtSpU7n55psB2L17N8Bk920bbrqzhbAP+EpETAHOBq6SdBqwGFgTEZOBNfmafG8+MBWYA9wqaUTO6zZgETA5H3OyvhB4ISJOBm4Evt4H62ZW1ciRI/nmN7/JM888w+OPP863vvUttmzZQmNjI8Ae920bbroMhIhoiYj/l8N7gGeACcCFwLIcbRlwUQ5fCCyPiNcjYjvQBMyUVA+MjojHIiKA75ZN0z6vu4FZ7b+wzPpLfX09Z5xxBgBHHXUUU6ZM4Ze//CUrV64E+HWO5r5tw0aPjiHk5u7pwBNAXUS0QBEawLgcbQLwXMlkzVmbkMPl9Q7TRMQ+4CXguArLXyRpvaT1bW1tPWm6WVU7duzgqaee4qyzzqK1tRVgL7hv2/DS7UCQdCTwfeDqiHi52qgValGlXm2ajoWIpRHREBENY8eO7arJZt3yyiuvcMkll3DTTTcxevToaqO6b9uQ1q1AkPQ2ijD4+4j4P1luzU1l8nlX1puBE0omnwjszPrECvUO00gaCRwN7O7pypj11N69e7nkkkv49Kc/zSc+8QkA6urqAN4G7ts2vHTnLCMB3waeiYi/KnlrFbAghxcAK0vq8/PsipMoDrCty03vPZLOznleUTZN+7wuBR7OfbFm/SYiWLhwIVOmTOHLX/7ym/W5c+fCW7t13Ldt2BjZjXE+APwOsFHShqz9CdAIrJC0EHgWuAwgIjZLWgFsoThD6aqI2J/TfR64HTgcuD8fUATOHZKaKH49zT+41TLr2tq1a7njjjt4z3vew/Tp0wH46le/yuLFi1myZMloSdtw37ZhpMtAiIgfUXk/KMCsTqa5AbihQn09MK1C/TXyS2c2UM455xyq/Fj/WUQ0lBfdt20o85XKZmYGOBDMzCw5EMzMDHAgmJlZciCYmRngQDAzs+RAMDMzwIFgZmbJgWBmZoADwczMkgPBzMwAB4KZmSUHgpmZAQ4EMzNLDgQzMwMcCGZmlhwIZmYGOBDMzCw5EMzMDHAgmJlZciCYmRngQDAzs+RAMDMzwIFgZmbJgWBmZoADwczMkgPBzMwAB4KZmSUHgpmZAQ4EMzNLDgQzMwMcCGZmlhwIZmYGOBDMzCx1GQiSviNpl6RNJbUxkh6UtC2fjy157xpJTZK2Sjq/pD5D0sZ87xZJyvooSXdl/QlJk/p4Hc0q+uxnP8u4ceOYNm3am7Xdu3cze/ZsgGnu2zbcdGcL4XZgTlltMbAmIiYDa/I1kk4D5gNTc5pbJY3IaW4DFgGT89E+z4XACxFxMnAj8PXeroxZT1x55ZWsXr26Q62xsZFZs2YBbMJ924aZLgMhIh4FdpeVLwSW5fAy4KKS+vKIeD0itgNNwExJ9cDoiHgsIgL4btk07fO6G5jV/gvLrD+de+65jBkzpkNt5cqVLFiwoP2l+7YNK709hlAXES0A+Twu6xOA50rGa87ahBwur3eYJiL2AS8Bx1VaqKRFktZLWt/W1tbLppt1rrW1lfr6esB924afvj6oXOnXT1SpV5vmwGLE0ohoiIiGsWPH9rKJZr3ivm1DXm8DoTU3lcnnXVlvBk4oGW8isDPrEyvUO0wjaSRwNAfuojIbEHV1dbS0tADu2zb89DYQVgHtO1oXACtL6vPz7IqTKA6wrctN7z2Szs59qFeUTdM+r0uBh3NfrNmAmzt3LsuWte/2d9+24WVkVyNIuhM4DzheUjNwHdAIrJC0EHgWuAwgIjZLWgFsAfYBV0XE/pzV5ynOWDocuD8fAN8G7pDURPHraX6frJlZFy6//HIeeeQRnn/+eSZOnMj111/P4sWLmTdvHsA0in3+7ts2bHQZCBFxeSdvzepk/BuAGyrU11N8ycrrr5FfOrOBdOedd1asr1mzBkmbIqJDH3fftqHOVyqbmRngQDAzs+RAMDMzwIFgZmbJgWBmZoADwczMkgPBzMwAB4KZmSUHgpmZAQ4EMzNLXd66wvrHpMX31roJZv3CffvQ5S0EMzMDHAhmZpYcCGZmBjgQzMwsORDMzAxwIJiZWXIgmJkZ4EAwM7PkQDAzM8CBYGZmyYFgZmaAA8HMzJIDwczMAAeCmZkl3/7aqurtrYx3NH68j1ti1rd607eHer/2FoKZmQEOBDMzSw4EMzMDHAhmZpYcCGZmBjgQzMwsORDMzAxwIJiZWRo0gSBpjqStkpokLa51e8z6ivu2HSoGxZXKkkYA3wJmA83AjyWtiogttW1Z9/T2al4b+g7lvu1+PfwMli2EmUBTRPwiIv4dWA5cWOM2mfUF9207ZAyKLQRgAvBcyetm4KzykSQtAhbly1ckbR2AtvWn44Hna92IPtJhXfT1Grakb/x2H82nP/t2rftPrZc/4G2o0K9r/Rn0ZvkndvbGYAkEVajFAYWIpcDS/m/OwJC0PiIaat2OvjCU1gWK9emrWVWo9UnfrvVnXuvlD4Y2DLXlD5ZdRs3ACSWvJwI7a9QWs77kvm2HjMESCD8GJks6SdLbgfnAqhq3yawvuG/bIWNQ7DKKiH2SvgD8EBgBfCciNte4WQNhyOz+YmitC/TR+vRz3671Z17r5UPt2zCklq+IA3ZnmpnZMDRYdhmZmVmNORDMzAxwIAwYSTskbZS0of2URkljJD0oaVs+H1vrdnZG0nck7ZK0qaTWafslXZO3atgq6fzatLpznazPn0n6Zf6NNkj6WMl7g2J9JF0mabOkNyQ1lL034G2s9pn183JrfjuQSt/pfl5ej76DveFAGFgfjIjpJecNLwbWRMRkYE2+HqxuB+aU1Sq2X9JpFGfTTM1pbs1bOAwmt3Pg+gDcmH+j6RFxHwy69dkEfAJ4tLRY4zYe8Jn1p5LbgXwUOA24PNe/Fsq/0/3pdrr5HewtB0JtXQgsy+FlwEW1a0p1EfEosLus3Fn7LwSWR8TrEbEdaKK4hcOg0cn6dGbQrE9EPBMRla5iHjRtHADD8nYgPfwO9ooDYeAE8ICkJ/M2BQB1EdECkM/jata63ums/ZVu1zBhgNvWW1+Q9JPcPG/f/D4U1qeWbaz0mfWnwfL3qPSdHmh9+m+IA2HgfCAizqDYzL1K0rm1blA/6tbtGgah24DfAqYDLcA3sz6g6yPpIUmbKjyq/QrutzZ20Z7OPrP+NFj615D7Tg+KC9OGg4jYmc+7JP2AYrO3VVJ9RLRIqgd21bSRPddZ+w/J2zVERGv7sKS/Be7JlwO6PhHx4V5M1m9t7G57yj6z/jQo+lcn3+lHq0/V5/r03xBvIQwASUdIOqp9GPgIxcHBVcCCHG0BsLI2Ley1ztq/CpgvaZSkk4DJwLoatK9H8gvV7mKKvxEcGutTkzZW+cz6U81vB1LlOz3Q+vbfkIjwo58fwLuBp/OxGbg268dRnBmwLZ/H1LqtVdbhTopdAnspfqEtrNZ+4Frg58BW4KO1bn831+cOYCPwk/yi1Q+29aH4R7cZeB1oBX5YyzZW+8z6ebkfA36W63ttDf4OFb/T/bzMHn0He/PwrSvMzAzwLiMzM0sOBDMzAxwIZmaWHAhmZgY4EMzMLDkQzMwMcCCYmVn6/ya6vfOcpnsGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = QM9(root, target, radius, \"train\", lmax_attr, feature_type)\n",
    "print(\"length\", len(train_dataset))\n",
    "ys = np.array([data.y.item() for data in train_dataset])\n",
    "mean, mad = train_dataset.calc_stats()\n",
    "\n",
    "for item in train_dataset:\n",
    "    print(item.edge_index)\n",
    "    break\n",
    "\n",
    "print(\"mean\", mean, \"mad\", mad)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(train_dataset.target)\n",
    "plt.hist(ys)\n",
    "plt.subplot(122)\n",
    "plt.title(train_dataset.target + \" standardised\")\n",
    "plt.hist((ys - mean)/mad)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = make_dataloader(train_dataset, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for valid set with radius=2, l_attr=3 and one_hot features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133885/133885 [01:09<00:00, 1937.55it/s]\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 17748\n",
      "tensor([[1, 2, 0, 2, 0, 1],\n",
      "        [0, 0, 1, 1, 2, 2]])\n",
      "mean 75.37343134473298 mad 6.272772235374586\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW2klEQVR4nO3dfbRkVX3m8e9jIwgICtJg0w12E1sjkhlfOsCMxJkVTGjRiK7IhMxKxMQJGQcjTDRJE2cyTiaMOBpNWBMwRI2YMRLiS+iFgwFRYmSBTKMYXlpCQyO0tNAaCPiy0Ca/+aN2Z5WX27frNlV1L+zvZ62z7ql9Xvbe5+567qlzquqmqpAk9eFJC90ASdL0GPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9B9Hkrw+yRfGva6euHocM0nuTPKyMe6vkjy7zb8vyX8d177bPv9tki3j3Odc9phWRZIEgxAFVlfVpoVuy3xV1X9c6DY8Vp7pSxKQpIuTYEN/EUqyLsntSR5KckuS1+xkvUry5iR3JPlmkncledKMdd6d5P4km5O8fKj8l5JsbHXckeRXJ90vTcao46WtO5Uxk+TZSf4myT+2ev6ilX++rfKVJN9O8nNJDkhyaZJtrd5Lk6wY2tdVSf5Hkqtb3ZcnOWho+S8m+VqSbyV524x2HJ3kmiQPJNma5H8n2XPG8Tg9yW3Aba3sN9q69yT55Rn7+1CS32vzB7W2PpDkH5L87Y5jmeTQJB9vfdqc5M1D+9i77ef+JLcAP76z4zgRVeW0yCbgZOBQBn+Ufw74DrAMeD3whaH1CvgccCBwOPD3wH9oy14P/AD4FWAJ8EbgHiBt+SuAHwEC/Bvgu8CLFrrvTuMbL0PjYOpjBvgo8LbWpqcAx81ow7OHHj8D+FlgH2A/4C+BvxpafhVwO/AcYO/2+Jy27Ejg28BLgb2A9wDbgZe15S8GjmVwKXslsBE4c0ZbrmjHY29gLXAvcBSwL/Dnw+0FPgT8Xpt/B/A+4Mlt+ol2bJ4EXA/8DrAncARwB3BC2+4c4G9bnYcBNwFbpjZeFnrAOo3wS4IbgJN28gReO/T4PwFXtvnXA5uGlu3T1n/mTur4K+CMhe6r0/jGy9A4mPqYAT4MXACsmGXZD4X+LMtfANw/9Pgq4L/MaPOn2/zvABcNLdsX+P6O0J9l32cCn5zRlp8cevxB2h+U9vg5c4T+7wKXzOwLcAxw14yys4A/bfN3zPgdnDbN0PfyziKU5HVJbmgvGx9gcNZx0E5Wv3to/msMzvh2+MaOmar6bpt9aqvj5UmubS9LHwBOnKMOLWLzHC8wnTHzmwzOeq9LcvPMyyQz2r9Pkj9ul2geBD4PPD3JktnaxeAVxlPb/KHD/amq7wDfGtr3c9olmG+0ff/PWdo8fDwO5dHHZ2feBWwCLm+Xu9a18mcBh+74fbRj9dvAIbtRx9gZ+otMkmcBfwK8CXhGVT2dwcu/7GSTw4bmD2fwcnxXdewFfBx4N3BIq+P/zlGHFqndGC8whTFTVd+oql+pqkOBXwXOS3vb4yzeAjwXOKaq9mdwqYZd9GGHrQz1J8k+DC4X7XA+8FUG7xban0H4ztzv8FcN/9D+GByfWVXVQ1X1lqo6AvgZ4NeTHM8g0DdX1dOHpv2q6sT51jEJhv7isy+DQbgNBjfPGJy57cxvtBthhwFnAH8xQh17Mrj+uQ3Y3m7W/fRjarUWynzHC0xhzCQ5eehm7P2tjY+0x/cyuM69w37A94AHkhwI/LcR2rPDx4BXJjmu3aD9XX441/YDHgS+neRHGdynmMvFwOuTHNn+gOy0LUle2W5Yp9XxSJuuAx5M8lvtpu2SJEcl2XHD9mLgrPY7WAH82jz6+5gZ+otMVd0C/D5wDYMnx48BV8+xySUMbhrdAHwK+MAIdTwEvJnB4Lsf+PfA+sfSbi2M3RgvMJ0x8+PAF5N8u613RlVtbsveDlzYLn38O+APGNxE/SZwLfDpXbVnqF03A6czuOG6tbVt+INOb21tfYjBK6I5/8BV1WWtPZ9lcOnms3Osvhr4DIMbydcA51XVVVX1CIMz/xcAm1u/3g88rW333xlc0tkMXA782Sh9HZcdd+X1OJTH8YdctDAcM/JMX5I6YuhLUke8vCNJHfFMX5I6sui/YOiggw6qlStXLnQz9AR1/fXXf7Oqlk67Xse1Jmmucb3oQ3/lypVs2LBhoZuhJ6gkU/005A6Oa03SXOPayzuS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRRf+JXE3HynWfmvc2d57zigm0RBqf3RnX8MQe257pS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHRkp9JP85yQ3J7kpyUeTPCXJgUmuSHJb+3nA0PpnJdmU5NYkJwyVvzjJjW3ZuUkyiU5Jo3jve98L8HzHtXqyy9BPshx4M7Cmqo4ClgCnAOuAK6tqNXBle0ySI9vy5wNrgfOSLGm7Ox84DVjdprVj7Y00oq9//euce+65ALc4rtWTUS/v7AHsnWQPYB/gHuAk4MK2/ELg1W3+JOCiqnq4qjYDm4CjkywD9q+qa6qqgA8PbSNN3fbt2wGe5LhWT3YZ+lX1deDdwF3AVuAfq+py4JCq2trW2Qoc3DZZDtw9tIstrWx5m59Z/ihJTkuyIcmGbdu2za9H0giWL1/OW9/6VoB/geNaHRnl8s4BDM5yVgGHAvsm+YW5NpmlrOYof3Rh1QVVtaaq1ixdunRXTZTm7f777+eSSy4BuBHHtToyyuWdlwGbq2pbVf0A+ATwr4F720tb2s/72vpbgMOGtl/B4GXzljY/s1yaus985jOsWrUKYLvjWj0ZJfTvAo5Nsk97V8LxwEZgPXBqW+dU4JI2vx44JcleSVYxuLF1XXup/FCSY9t+Xje0jTRVhx9+ONdeey0Mruk7rtWNUa7pfxH4GPAlBi+FnwRcAJwD/FSS24Cfao+pqpuBi4FbgE8Dp1fVI213bwTez+Am2O3AZePsjDSqY445hte+9rUAz8NxrY5k8IaDxWvNmjW1YcOGhW7GE16v/yM3yfVVtWba9Tqup6PX/5E717j2E7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjuyx0A3QeK1c96mFboI0do7r8fFMX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVkpNBP8vQkH0vy1SQbk/yrJAcmuSLJbe3nAUPrn5VkU5Jbk5wwVP7iJDe2ZecmySQ6Jc3DEse2ejLqmf4fAp+uqh8F/iWwEVgHXFlVq4Er22OSHAmcAjwfWAucl2RJ28/5wGnA6jatHVM/pN11GI5tdWSXoZ9kf+ClwAcAqur7VfUAcBJwYVvtQuDVbf4k4KKqeriqNgObgKOTLAP2r6prqqqADw9tI03dgw8+CLAfjm11ZJQz/SOAbcCfJvlykvcn2Rc4pKq2ArSfB7f1lwN3D22/pZUtb/Mzyx8lyWlJNiTZsG3btnl1SBrVHXfcAbCdKY1tx7UWg1FCfw/gRcD5VfVC4Du0l7s7Mdu1zJqj/NGFVRdU1ZqqWrN06dIRmijN3/bt2wH2YUpj23GtxWCU0N8CbKmqL7bHH2PwR+De9rKW9vO+ofUPG9p+BXBPK18xS7m0IFasWAHwfce2erLL0K+qbwB3J3luKzoeuAVYD5zayk4FLmnz64FTkuyVZBWDm1rXtZfJDyU5tr2z4XVD20hT98xnPhPg+45t9WTUb9n8NeAjSfYE7gB+icEfjIuTvAG4CzgZoKpuTnIxgyfPduD0qnqk7eeNwIeAvYHL2iQtpLtwbKsjI4V+Vd0ArJll0fE7Wf9s4OxZyjcAR82jfdKkfa+qHNvqhp/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMjh36SJUm+nOTS9vjAJFckua39PGBo3bOSbEpya5IThspfnOTGtuzcJBlvd6T5c1yrJ/M50z8D2Dj0eB1wZVWtBq5sj0lyJHAK8HxgLXBekiVtm/OB04DVbVr7mFovPXaH4LhWR0YK/SQrgFcA7x8qPgm4sM1fCLx6qPyiqnq4qjYDm4CjkywD9q+qa6qqgA8PbSNN3ZYtWwCehuNaHRn1TP8PgN8E/mmo7JCq2grQfh7cypcDdw+tt6WVLW/zM8sfJclpSTYk2bBt27YRmyjNz5lnngmDcei4Vjd2GfpJXgncV1XXj7jP2a5n1hzljy6suqCq1lTVmqVLl45YrTS6Sy+9lIMPPhjguyNu4rjWE8IeI6zzEuBVSU4EngLsn+T/APcmWVZVW9tL3Pva+luAw4a2XwHc08pXzFIuTd3VV1/N+vXrAX4MuAjHtTqxyzP9qjqrqlZU1UoGN7I+W1W/AKwHTm2rnQpc0ubXA6ck2SvJKgY3tq5rL5UfSnJse3fD64a2kabqHe94x45r+jfiuFZHRjnT35lzgIuTvAG4CzgZoKpuTnIxcAuwHTi9qh5p27wR+BCwN3BZm6TFxHGtJ7R5hX5VXQVc1ea/BRy/k/XOBs6epXwDcNR8GylNkuNaPfETuZLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVkl6Gf5LAkn0uyMcnNSc5o5QcmuSLJbe3nAUPbnJVkU5Jbk5wwVP7iJDe2ZecmyWS6Je3a3XffDfAcx7Z6MsqZ/nbgLVX1POBY4PQkRwLrgCurajVwZXtMW3YK8HxgLXBekiVtX+cDpwGr27R2jH2R5mWPPfYA2OLYVk92GfpVtbWqvtTmHwI2AsuBk4AL22oXAq9u8ycBF1XVw1W1GdgEHJ1kGbB/VV1TVQV8eGgbaeqWLVsG8F1wbKsf87qmn2Ql8ELgi8AhVbUVBn8YgIPbasuBu4c229LKlrf5meWz1XNakg1JNmzbtm0+TZR2yzTGtuNai8HIoZ/kqcDHgTOr6sG5Vp2lrOYof3Rh1QVVtaaq1ixdunTUJkq7ZVpj23GtxWCk0E/yZAZPio9U1Sda8b3tZS3t532tfAtw2NDmK4B7WvmKWcqlhRQc2+rIKO/eCfABYGNVvWdo0Xrg1DZ/KnDJUPkpSfZKsorBTa3r2svkh5Ic2/b5uqFtpKkbXH7nWTi21ZE9RljnJcAvAjcmuaGV/TZwDnBxkjcAdwEnA1TVzUkuBm5h8M6f06vqkbbdG4EPAXsDl7VJWhBXX301wDOAn3Rsqxe7DP2q+gKzX7MEOH4n25wNnD1L+QbgqPk0UJqU4447DuD6qlozy2LHtp6Q/ESuJHXE0Jekjhj6ktQRQ1+SOmLoS1JHRnnLpjSrles+tVvb3XnOK8bcEmm8nshj2zN9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjvgtm4vU7n7Ln7TYObYXlmf6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkem/j9yk6wF/hBYAry/qs6Zdhumyf8H2g/Hth4Ppnqmn2QJ8EfAy4EjgZ9PcuQ02yBNgmNbjxfTPtM/GthUVXcAJLkIOAm4ZcrtmDfPasZnd4/lnee8YswtGSvHth4XY3vaob8cuHvo8RbgmJkrJTkNOK09/HaSW6fQtmEHAd+ccp0LXfei73PeOZG6nzum/exybI9xXC/k72oui7VdsHjbdhDwzQmM7WftbMG0Qz+zlNWjCqouAC6YfHNml2RDVa3pqe4e+7yj7nHtapayHxrb4xrXC3m85rJY2wWLt20L0a5pv3tnC3DY0OMVwD1TboM0CY5tPS5MO/T/H7A6yaokewKnAOun3AZpEhzbelyY6uWdqtqe5E3AXzN4W9sHq+rmabZhRAt2aWkB6+6xz2Ore8pjeyGP11wWa7tg8bZt6u1K1aMuqUuSnqD8RK4kdcTQl6SOdB/6SQ5L8rkkG5PcnOSMVv72JF9PckObTpxA3XcmubHtf0MrOzDJFUluaz8PmEC9zx3q1w1JHkxy5qT6nOSDSe5LctNQ2U77meSsJJuS3JrkhDHX+64kX03yd0k+meTprXxlku8N9f19u1vvpCQ5uY3Rf0qyZsaysRyzMbRx4s+bebZnbTsmm5KsW8i2zDTb838qqqrrCVgGvKjN7wf8PYOP0b8deOuE674TOGhG2f8C1rX5dcA7J9yGJcA3GHyYYyJ9Bl4KvAi4aVf9bMf+K8BewCrgdmDJGOv9aWCPNv/OoXpXDq+3GCfgeQw+THYVsGaofGzHbAxtnPjzZh5tWdKOxRHAnu0YHbnQ7Rpq36Oe/9OYuj/Tr6qtVfWlNv8QsJHBpysXyknAhW3+QuDVE67veOD2qvrapCqoqs8D/zCjeGf9PAm4qKoerqrNwCYGX3Ewlnqr6vKq2t4eXsvg/fSPC1W1sapm+xTv2I7ZE8w/fzVGVX0f2PHVGF3rPvSHJVkJvBD4Yit6U7sM8MFJXGZh8InNy5Nc3z6iD3BIVW2FwR8k4OAJ1DvsFOCjQ48n3ecddtbP2b7OYFJ/hH8ZuGzo8aokX07yN0l+YkJ1TsI0j9kopjWGdmWxHZeZZnv+T5yh3yR5KvBx4MyqehA4H/gR4AXAVuD3J1DtS6rqRQy+mfH0JC+dQB071T5E9CrgL1vRNPq8y2bNUjb29xUneRuwHfhIK9oKHF5VLwR+HfjzJPuPu94R2vWZJDfNMs11hjqVYzZiGxfDGPrnps5Stpjeo74gz/+pf5/+YpTkyQwC/yNV9QmAqrp3aPmfAJeOu96quqf9vC/JJxm8HL03ybKq2ppkGXDfuOsd8nLgSzv6Oo0+D9lZPyf+dQZJTgVeCRxf7eJqVT0MPNzmr09yO/AcYHo32AZ1v2w3NpvqV0CM2sYpjKFdWdRfjbGT5//nJ11v92f6SQJ8ANhYVe8ZKl82tNprgJtmbvsY6903yX475hncYLyJwUf3T22rnQpcMs56Z/h5hi7tTLrPM+ysn+uBU5LslWQVsBq4blyVZvCPTn4LeFVVfXeofGkG34lPkiNavXeMq94Jm+gxm48pj6FdWbRfjTHH83/yFvoO9kJPwHEMXvL9HXBDm04E/gy4sZWvB5aNud4jGLyb4CvAzcDbWvkzgCuB29rPAyfU732AbwFPGyqbSJ8Z/GHZCvyAwdnXG+bqJ/A2Bu+6uBV4+Zjr3cTgOu+O3/X72ro/234PXwG+BPzMQo/NWfrzmtaPh4F7gb8e9zEbQxsn+rzZjfacyOAdebfveI4thmlnz/9pTH4NgyR1pPvLO5LUE0Nfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdeT/A4DrnAKAsdKtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_dataset = QM9(root, target, radius, \"valid\", lmax_attr, feature_type)\n",
    "print(\"length\", len(valid_dataset))\n",
    "ys = np.array([data.y.item() for data in valid_dataset])\n",
    "mean, mad = valid_dataset.calc_stats()\n",
    "\n",
    "for item in valid_dataset:\n",
    "    print(item.edge_index)\n",
    "    break\n",
    "\n",
    "print(\"mean\", mean, \"mad\", mad)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(valid_dataset.target)\n",
    "plt.hist(ys)\n",
    "plt.subplot(122)\n",
    "plt.title(valid_dataset.target + \" standardised\")\n",
    "plt.hist((ys - mean)/mad)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = make_dataloader(valid_dataset, batch_size, num_workers, train=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for test set with radius=2, l_attr=3 and one_hot features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133885/133885 [00:59<00:00, 2249.64it/s]\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length 13083\n",
      "tensor([[1, 3, 4, 5, 0, 2, 6, 1, 0, 4, 5, 0, 3, 5, 0, 3, 4, 1],\n",
      "        [0, 0, 0, 0, 1, 1, 1, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6]])\n",
      "mean 75.27169685054699 mad 6.34405899560443\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = QM9(root, target, radius, \"test\", lmax_attr, feature_type)\n",
    "print(\"length\", len(test_dataset))\n",
    "ys = np.array([data.y.item() for data in test_dataset])\n",
    "mean, mad = test_dataset.calc_stats()\n",
    "\n",
    "for item in test_dataset:\n",
    "    print(item.edge_index)\n",
    "    break\n",
    "\n",
    "print(\"mean\", mean, \"mad\", mad)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(test_dataset.target)\n",
    "plt.hist(ys)\n",
    "plt.subplot(122)\n",
    "plt.title(test_dataset.target + \" standardised\")\n",
    "plt.hist((ys - mean)/mad)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = make_dataloader(test_dataset, batch_size, num_workers, train=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train set statistics\n",
    "target_mean, target_mad = train_loader.dataset.calc_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the group representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn.o3 import Irreps, spherical_harmonics\n",
    "\n",
    "input_irreps = Irreps(\"5x0e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_irreps = Irreps(\"1x0e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attr_irreps = Irreps.spherical_harmonics(3)\n",
    "node_attr_irreps = Irreps.spherical_harmonics(3)\n",
    "additional_message_irreps = Irreps(\"1x0e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hidden irreps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn.o3 import Irreps\n",
    "from e3nn.o3 import Linear, spherical_harmonics, FullyConnectedTensorProduct\n",
    "\n",
    "\n",
    "def BalancedIrreps(lmax, vec_dim, sh_type=True):\n",
    "    \"\"\" Allocates irreps equally along channel budget, resulting\n",
    "        in unequal numbers of irreps in ratios of 2l_i + 1 to 2l_j + 1.\n",
    "    Parameters\n",
    "    ----------\n",
    "    lmax : int\n",
    "        Maximum order of irreps.\n",
    "    vec_dim : int\n",
    "        Dim of feature vector.\n",
    "    sh_type : bool\n",
    "        if true, use spherical harmonics. Else the full set of irreps (with redundance).\n",
    "    Returns\n",
    "    -------\n",
    "    Irreps\n",
    "        Resulting irreps for feature vectors.\n",
    "    \"\"\"\n",
    "    irrep_spec = \"0e\"\n",
    "    for l in range(1, lmax + 1):\n",
    "        if sh_type:\n",
    "            irrep_spec += \" + {0}\".format(l) + ('e' if (l % 2) == 0 else 'o')\n",
    "        else:\n",
    "            irrep_spec += \" + {0}e + {0}o\".format(l)\n",
    "    irrep_spec_split = irrep_spec.split(\" + \")\n",
    "    dims = [int(irrep[0]) * 2 + 1 for irrep in irrep_spec_split]\n",
    "    # Compute ratios\n",
    "    ratios = [1 / dim for dim in dims]\n",
    "    # Determine how many copies per irrep\n",
    "    irrep_copies = [int(vec_dim * r / len(ratios)) for r in ratios]\n",
    "    # Determine the current effective irrep sizes\n",
    "    irrep_dims = [n * dim for (n, dim) in zip(irrep_copies, dims)]\n",
    "    # Add trivial irreps until the desired size is reached\n",
    "    irrep_copies[0] += vec_dim - sum(irrep_dims)\n",
    "\n",
    "    # Convert to string\n",
    "    str_out = ''\n",
    "    for (spec, dim) in zip(irrep_spec_split, irrep_copies):\n",
    "        str_out += str(dim) + 'x' + spec\n",
    "        str_out += ' + '\n",
    "    str_out = str_out[:-3]\n",
    "    # Generate the irrep\n",
    "    return Irreps(str_out)\n",
    "\n",
    "\n",
    "def WeightBalancedIrreps(irreps_in1_scalar, irreps_in2, sh=True, lmax=None):\n",
    "    \"\"\"Determines an irreps_in1 type of order irreps_in2.lmax that when used in a tensor product\n",
    "    irreps_in1 x irreps_in2 -> irreps_in1\n",
    "    would have the same number of weights as for a standard linear layer, e.g. a tensor product\n",
    "    irreps_in1_scalar x \"1x0e\" -> irreps_in1_scalar\n",
    "    Parameters\n",
    "    ----------\n",
    "    irreps_in1_scalar : o3.Irreps\n",
    "        Number of hidden features, represented by zeroth order irreps.\n",
    "    irreps_in2 : o3.Irreps\n",
    "        Irreps related to edge attributes.\n",
    "    sh : bool\n",
    "        if true, yields equal number of every order. Else returns balanced irrep.\n",
    "    lmax : int\n",
    "        Maximum order irreps to be considered.\n",
    "    Returns\n",
    "    -------\n",
    "    o3.Irreps\n",
    "        Irreps for hidden feaure vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    n = 1\n",
    "    if lmax == None:\n",
    "        lmax = irreps_in2.lmax\n",
    "    irreps_in1 = (Irreps.spherical_harmonics(lmax) * n).sort().irreps.simplify() if sh else BalancedIrreps(lmax, n)\n",
    "    weight_numel1 = FullyConnectedTensorProduct(irreps_in1, irreps_in2, irreps_in1).weight_numel\n",
    "    weight_numel_scalar = FullyConnectedTensorProduct(irreps_in1_scalar, Irreps(\"1x0e\"), irreps_in1_scalar).weight_numel\n",
    "    while weight_numel1 < weight_numel_scalar:  # TODO: somewhat suboptimal implementation...\n",
    "        n += 1\n",
    "        irreps_in1 = (Irreps.spherical_harmonics(lmax) * n).sort().irreps.simplify() if sh else BalancedIrreps(lmax, n)\n",
    "        weight_numel1 = FullyConnectedTensorProduct(irreps_in1, irreps_in2, irreps_in1).weight_numel\n",
    "    print('Determined irrep type:', irreps_in1)\n",
    "    return Irreps(irreps_in1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determined irrep type: 36x0e+36x1o+36x2e\n"
     ]
    }
   ],
   "source": [
    "hidden_irreps = WeightBalancedIrreps(\n",
    "            Irreps(\"{}x0e\".format(hidden_features)), node_attr_irreps, sh=True, lmax=lmax_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEGNN Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, global_add_pool\n",
    "from e3nn.nn import BatchNorm, Gate\n",
    "from e3nn.o3 import Irreps, Linear, spherical_harmonics, FullyConnectedTensorProduct\n",
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class O3TensorProduct(nn.Module):\n",
    "    \"\"\" A bilinear layer, computing CG tensorproduct and normalising them.\n",
    "    Parameters\n",
    "    ----------\n",
    "    irreps_in1 : o3.Irreps\n",
    "        Input irreps.\n",
    "    irreps_out : o3.Irreps\n",
    "        Output irreps.\n",
    "    irreps_in2 : o3.Irreps\n",
    "        Second input irreps.\n",
    "    tp_rescale : bool\n",
    "        If true, rescales the tensor product.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, irreps_in1, irreps_out, irreps_in2=None, tp_rescale=True) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.irreps_in1 = irreps_in1\n",
    "        self.irreps_out = irreps_out\n",
    "        # Init irreps_in2\n",
    "        if irreps_in2 == None:\n",
    "            self.irreps_in2_provided = False\n",
    "            self.irreps_in2 = Irreps(\"1x0e\")\n",
    "        else:\n",
    "            self.irreps_in2_provided = True\n",
    "            self.irreps_in2 = irreps_in2\n",
    "        self.tp_rescale = tp_rescale\n",
    "\n",
    "        # Build the layers\n",
    "        self.tp = FullyConnectedTensorProduct(\n",
    "            irreps_in1=self.irreps_in1,\n",
    "            irreps_in2=self.irreps_in2,\n",
    "            irreps_out=self.irreps_out, shared_weights=True, normalization='component')\n",
    "\n",
    "        # For each zeroth order output irrep we need a bias\n",
    "        # So first determine the order for each output tensor and their dims\n",
    "        self.irreps_out_orders = [int(irrep_str[-2]) for irrep_str in str(irreps_out).split('+')]\n",
    "        self.irreps_out_dims = [int(irrep_str.split('x')[0]) for irrep_str in str(irreps_out).split('+')]\n",
    "        self.irreps_out_slices = irreps_out.slices()\n",
    "        # Store tuples of slices and corresponding biases in a list\n",
    "        self.biases = []\n",
    "        self.biases_slices = []\n",
    "        self.biases_slice_idx = []\n",
    "        for slice_idx in range(len(self.irreps_out_orders)):\n",
    "            if self.irreps_out_orders[slice_idx] == 0:\n",
    "                out_slice = irreps_out.slices()[slice_idx]\n",
    "                out_bias = torch.zeros(self.irreps_out_dims[slice_idx], dtype=self.tp.weight.dtype)\n",
    "                self.biases += [out_bias]\n",
    "                self.biases_slices += [out_slice]\n",
    "                self.biases_slice_idx += [slice_idx]\n",
    "\n",
    "        # Initialize the correction factors\n",
    "        self.slices_sqrt_k = {}\n",
    "\n",
    "        # Initialize similar to the torch.nn.Linear\n",
    "        self.tensor_product_init()\n",
    "        # Adapt parameters so they can be applied using vector operations.\n",
    "        self.vectorise()\n",
    "\n",
    "    def tensor_product_init(self) -> None:\n",
    "        with torch.no_grad():\n",
    "            # Determine fan_in for each slice, it could be that each output slice is updated via several instructions\n",
    "            slices_fan_in = {}  # fan_in per slice\n",
    "            for weight, instr in zip(self.tp.weight_views(), self.tp.instructions):\n",
    "                slice_idx = instr[2]\n",
    "                mul_1, mul_2, mul_out = weight.shape\n",
    "                fan_in = mul_1 * mul_2\n",
    "                slices_fan_in[slice_idx] = (slices_fan_in[slice_idx] +\n",
    "                                            fan_in if slice_idx in slices_fan_in.keys() else fan_in)\n",
    "            # Do the initialization of the weights in each instruction\n",
    "            for weight, instr in zip(self.tp.weight_views(), self.tp.instructions):\n",
    "                # The tensor product in e3nn already normalizes proportional to 1 / sqrt(fan_in), and the weights are by\n",
    "                # default initialized with unif(-1,1). However, we want to be consistent with torch.nn.Linear and\n",
    "                # initialize the weights with unif(-sqrt(k),sqrt(k)), with k = 1 / fan_in\n",
    "                slice_idx = instr[2]\n",
    "                if self.tp_rescale:\n",
    "                    sqrt_k = 1 / sqrt(slices_fan_in[slice_idx])\n",
    "                else:\n",
    "                    sqrt_k = 1.\n",
    "                weight.data.uniform_(-sqrt_k, sqrt_k)\n",
    "                self.slices_sqrt_k[slice_idx] = (self.irreps_out_slices[slice_idx], sqrt_k)\n",
    "\n",
    "            # Initialize the biases\n",
    "            for (out_slice_idx, out_slice, out_bias) in zip(self.biases_slice_idx, self.biases_slices, self.biases):\n",
    "                sqrt_k = 1 / sqrt(slices_fan_in[out_slice_idx])\n",
    "                out_bias.uniform_(-sqrt_k, sqrt_k)\n",
    "\n",
    "    def vectorise(self):\n",
    "        \"\"\" Adapts the bias parameter and the sqrt_k corrections so they can be applied using vectorised operations \"\"\"\n",
    "\n",
    "        # Vectorise the bias parameters\n",
    "        if len(self.biases) > 0:\n",
    "            with torch.no_grad():\n",
    "                self.biases = torch.cat(self.biases, dim=0)\n",
    "            self.biases = nn.Parameter(self.biases)\n",
    "\n",
    "            # Compute broadcast indices.\n",
    "            bias_idx = torch.LongTensor()\n",
    "            for slice_idx in range(len(self.irreps_out_orders)):\n",
    "                if self.irreps_out_orders[slice_idx] == 0:\n",
    "                    out_slice = self.irreps_out.slices()[slice_idx]\n",
    "                    bias_idx = torch.cat((bias_idx, torch.arange(out_slice.start, out_slice.stop).long()), dim=0)\n",
    "\n",
    "            self.register_buffer(\"bias_idx\", bias_idx, persistent=False)\n",
    "        else:\n",
    "            self.biases = None\n",
    "\n",
    "        # Now onto the sqrt_k correction\n",
    "        sqrt_k_correction = torch.zeros(self.irreps_out.dim)\n",
    "        for instr in self.tp.instructions:\n",
    "            slice_idx = instr[2]\n",
    "            slice, sqrt_k = self.slices_sqrt_k[slice_idx]\n",
    "            sqrt_k_correction[slice] = sqrt_k\n",
    "\n",
    "        # Make sure bias_idx and sqrt_k_correction are on same device as module\n",
    "        self.register_buffer(\"sqrt_k_correction\", sqrt_k_correction, persistent=False)\n",
    "\n",
    "    def forward_tp_rescale_bias(self, data_in1, data_in2=None) -> torch.Tensor:\n",
    "        if data_in2 == None:\n",
    "            data_in2 = torch.ones_like(data_in1[:, 0:1])\n",
    "\n",
    "        data_out = self.tp(data_in1, data_in2)\n",
    "\n",
    "        # Apply corrections\n",
    "        if self.tp_rescale:\n",
    "            data_out /= self.sqrt_k_correction\n",
    "\n",
    "        # Add the biases\n",
    "        if self.biases is not None:\n",
    "            data_out[:, self.bias_idx] += self.biases\n",
    "        return data_out\n",
    "\n",
    "    def forward(self, data_in1, data_in2=None) -> torch.Tensor:\n",
    "        # Apply the tensor product, the rescaling and the bias\n",
    "        data_out = self.forward_tp_rescale_bias(data_in1, data_in2)\n",
    "        return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class O3TensorProductSwishGate(O3TensorProduct):\n",
    "    def __init__(self, irreps_in1, irreps_out, irreps_in2=None) -> None:\n",
    "        # For the gate the output of the linear needs to have an extra number of scalar irreps equal to the amount of\n",
    "        # non scalar irreps:\n",
    "        # The first type is assumed to be scalar and passed through the activation\n",
    "        irreps_g_scalars = Irreps(str(irreps_out[0]))\n",
    "        # The remaining types are gated\n",
    "        irreps_g_gate = Irreps(\"{}x0e\".format(irreps_out.num_irreps - irreps_g_scalars.num_irreps))\n",
    "        irreps_g_gated = Irreps(str(irreps_out[1:]))\n",
    "        # So the gate needs the following irrep as input, this is the output irrep of the tensor product\n",
    "        irreps_g = (irreps_g_scalars + irreps_g_gate + irreps_g_gated).simplify()\n",
    "\n",
    "        # Build the layers\n",
    "        super(O3TensorProductSwishGate, self).__init__(irreps_in1, irreps_g, irreps_in2)\n",
    "        if irreps_g_gated.num_irreps > 0:\n",
    "            self.gate = Gate(irreps_g_scalars, [nn.SiLU()], irreps_g_gate, [torch.sigmoid], irreps_g_gated)\n",
    "        else:\n",
    "            self.gate = nn.SiLU()\n",
    "\n",
    "    def forward(self, data_in1, data_in2=None) -> torch.Tensor:\n",
    "        # Apply the tensor product, the rescaling and the bias\n",
    "        data_out = self.forward_tp_rescale_bias(data_in1, data_in2)\n",
    "        # Apply the gate\n",
    "        data_out = self.gate(data_out)\n",
    "        # Return result\n",
    "        return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class O3SwishGate(torch.nn.Module):\n",
    "    def __init__(self, irreps_g_scalars, irreps_g_gate, irreps_g_gated) -> None:\n",
    "        super().__init__()\n",
    "        if irreps_g_gated.num_irreps > 0:\n",
    "            self.gate = Gate(irreps_g_scalars, [nn.SiLU()], irreps_g_gate, [torch.sigmoid], irreps_g_gated)\n",
    "        else:\n",
    "            self.gate = nn.SiLU()\n",
    "\n",
    "    def forward(self, data_in) -> torch.Tensor:\n",
    "        data_out = self.gate(data_in)\n",
    "        return data_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of Instance Normalization is to normalize each feature vector in the input tensor by its norm, which is invariant under orthonormal representations. The normalization is applied separately to each batch element and feature vector. In addition to normalization, Instance Normalization can also apply an affine transformation to each feature vector, consisting of a learned weight and bias parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNorm(nn.Module):\n",
    "    '''Instance normalization for orthonormal representations\n",
    "    It normalizes by the norm of the representations.\n",
    "    Note that the norm is invariant only for orthonormal representations.\n",
    "    Irreducible representations `wigner_D` are orthonormal.\n",
    "    Parameters\n",
    "    ----------\n",
    "    irreps : `Irreps`\n",
    "        representation\n",
    "    eps : float\n",
    "        avoid division by zero when we normalize by the variance\n",
    "    affine : bool\n",
    "        do we have weight and bias parameters\n",
    "    reduce : {'mean', 'max'}\n",
    "        method used to reduce\n",
    "    '''\n",
    "\n",
    "    def __init__(self, irreps, eps=1e-5, affine=True, reduce='mean', normalization='component'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.irreps = Irreps(irreps)\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "\n",
    "        num_scalar = sum(mul for mul, ir in self.irreps if ir.l == 0)\n",
    "        num_features = self.irreps.num_irreps\n",
    "\n",
    "        if affine:\n",
    "            self.weight = nn.Parameter(torch.ones(num_features))\n",
    "            self.bias = nn.Parameter(torch.zeros(num_scalar))\n",
    "        else:\n",
    "            self.register_parameter('weight', None)\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        assert isinstance(reduce, str), \"reduce should be passed as a string value\"\n",
    "        assert reduce in ['mean', 'max'], \"reduce needs to be 'mean' or 'max'\"\n",
    "        self.reduce = reduce\n",
    "\n",
    "        assert normalization in ['norm', 'component'], \"normalization needs to be 'norm' or 'component'\"\n",
    "        self.normalization = normalization\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__} ({self.irreps}, eps={self.eps})\"\n",
    "\n",
    "    def forward(self, input, batch):\n",
    "        '''evaluate\n",
    "        Parameters\n",
    "        ----------\n",
    "        input : `torch.Tensor`\n",
    "            tensor of shape ``(batch, ..., irreps.dim)``\n",
    "        Returns\n",
    "        -------\n",
    "        `torch.Tensor`\n",
    "            tensor of shape ``(batch, ..., irreps.dim)``\n",
    "        '''\n",
    "        # batch, *size, dim = input.shape  # TODO: deal with batch\n",
    "        # input = input.reshape(batch, -1, dim)  # [batch, sample, stacked features]\n",
    "        # input has shape [batch * nodes, dim], but with variable nr of nodes.\n",
    "        # the input batch slices this into separate graphs\n",
    "        dim = input.shape[-1]\n",
    "\n",
    "        fields = []\n",
    "        ix = 0\n",
    "        iw = 0\n",
    "        ib = 0\n",
    "\n",
    "        for mul, ir in self.irreps:  # mul is the multiplicity (number of copies) of some irrep type (ir)\n",
    "            d = ir.dim\n",
    "            field = input[:, ix: ix + mul * d]  # [batch * sample, mul * repr]\n",
    "            ix += mul * d\n",
    "\n",
    "            # [batch * sample, mul, repr]\n",
    "            field = field.reshape(-1, mul, d)\n",
    "\n",
    "            # For scalars first compute and subtract the mean\n",
    "            if ir.l == 0:\n",
    "                # Compute the mean\n",
    "                field_mean = global_mean_pool(field, batch).reshape(-1, mul, 1)  # [batch, mul, 1]]\n",
    "                # Subtract the mean\n",
    "                field = field - field_mean[batch]\n",
    "\n",
    "            # Then compute the rescaling factor (norm of each feature vector)\n",
    "            # Rescaling of the norms themselves based on the option \"normalization\"\n",
    "            if self.normalization == 'norm':\n",
    "                field_norm = field.pow(2).sum(-1)  # [batch * sample, mul]\n",
    "            elif self.normalization == 'component':\n",
    "                field_norm = field.pow(2).mean(-1)  # [batch * sample, mul]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid normalization option {}\".format(self.normalization))\n",
    "            # Reduction method\n",
    "            if self.reduce == 'mean':\n",
    "                field_norm = global_mean_pool(field_norm, batch)  # [batch, mul]\n",
    "            elif self.reduce == 'max':\n",
    "                field_norm = global_max_pool(field_norm, batch)  # [batch, mul]\n",
    "            else:\n",
    "                raise ValueError(\"Invalid reduce option {}\".format(self.reduce))\n",
    "\n",
    "            # Then apply the rescaling (divide by the sqrt of the squared_norm, i.e., divide by the norm\n",
    "            field_norm = (field_norm + self.eps).pow(-0.5)  # [batch, mul]\n",
    "\n",
    "            if self.affine:\n",
    "                weight = self.weight[None, iw: iw + mul]  # [batch, mul]\n",
    "                iw += mul\n",
    "                field_norm = field_norm * weight  # [batch, mul]\n",
    "\n",
    "            field = field * field_norm[batch].reshape(-1, mul, 1)  # [batch * sample, mul, repr]\n",
    "\n",
    "            if self.affine and d == 1:  # scalars\n",
    "                bias = self.bias[ib: ib + mul]  # [batch, mul]\n",
    "                ib += mul\n",
    "                field += bias.reshape(mul, 1)  # [batch * sample, mul, repr]\n",
    "\n",
    "            # Save the result, to be stacked later with the rest\n",
    "            fields.append(field.reshape(-1, mul * d))  # [batch * sample, mul * repr]\n",
    "\n",
    "        if ix != dim:\n",
    "            fmt = \"`ix` should have reached input.size(-1) ({}), but it ended at {}\"\n",
    "            msg = fmt.format(dim, ix)\n",
    "            raise AssertionError(msg)\n",
    "\n",
    "        output = torch.cat(fields, dim=-1)  # [batch * sample, stacked features]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEGNN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor initializes several layers for message passing and node updates. Specifically, it initializes two O3TensorProductSwishGate layers for computing messages, and two O3TensorProduct layers for updating node features. It also sets up normalisation, either batch or instance norm.\n",
    "\n",
    "The forward method takes node features, edge indices, edge features, node attributes, batch indices, and additional message features as input, and propagates messages along edges using the propagate method of MessagePassing. It then applies normalisation to the resulting node features.\n",
    "\n",
    "The message method computes messages using the message_layer_1 and message_layer_2 layers, and applies normalisation to the resulting messages. It takes input node features of sender and receiver nodes, edge attributes, and additional message features as input.\n",
    "\n",
    "The update method updates node features using the update_layer_1 and update_layer_2 layers, and adds a residual connection to the original node features. It takes messages, node features, and node attributes as input, and returns updated node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEGNNLayer(MessagePassing):\n",
    "    \"\"\"E(3) equivariant message passing layer.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_irreps,\n",
    "        hidden_irreps,\n",
    "        output_irreps,\n",
    "        edge_attr_irreps,\n",
    "        node_attr_irreps,\n",
    "        norm=None,\n",
    "        additional_message_irreps=None,\n",
    "    ):\n",
    "        super().__init__(node_dim=-2, aggr=\"add\")\n",
    "        self.hidden_irreps = hidden_irreps\n",
    "\n",
    "        message_input_irreps = (2 * input_irreps + additional_message_irreps).simplify()\n",
    "        update_input_irreps = (input_irreps + hidden_irreps).simplify()\n",
    "\n",
    "        self.message_layer_1 = O3TensorProductSwishGate(\n",
    "            message_input_irreps, hidden_irreps, edge_attr_irreps\n",
    "        )\n",
    "        self.message_layer_2 = O3TensorProductSwishGate(\n",
    "            hidden_irreps, hidden_irreps, edge_attr_irreps\n",
    "        )\n",
    "        self.update_layer_1 = O3TensorProductSwishGate(\n",
    "            update_input_irreps, hidden_irreps, node_attr_irreps\n",
    "        )\n",
    "        self.update_layer_2 = O3TensorProduct(\n",
    "            hidden_irreps, hidden_irreps, node_attr_irreps\n",
    "        )\n",
    "\n",
    "        self.setup_normalisation(norm)\n",
    "\n",
    "    def setup_normalisation(self, norm):\n",
    "        \"\"\"Set up normalisation, either batch or instance norm\"\"\"\n",
    "        self.norm = norm\n",
    "        self.feature_norm = None\n",
    "        self.message_norm = None\n",
    "\n",
    "        if norm == \"batch\":\n",
    "            self.feature_norm = BatchNorm(self.hidden_irreps)\n",
    "            self.message_norm = BatchNorm(self.hidden_irreps)\n",
    "        elif norm == \"instance\":\n",
    "            self.feature_norm = InstanceNorm(self.hidden_irreps)\n",
    "\n",
    "        self.feature_norm = InstanceNorm(self.hidden_irreps)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        edge_index,\n",
    "        edge_attr,\n",
    "        node_attr,\n",
    "        batch,\n",
    "        additional_message_features=None,\n",
    "    ):\n",
    "        \"\"\"Propagate messages along edges\"\"\"\n",
    "        x = self.propagate(\n",
    "            edge_index,\n",
    "            x=x,\n",
    "            node_attr=node_attr,\n",
    "            edge_attr=edge_attr,\n",
    "            additional_message_features=additional_message_features,\n",
    "        )\n",
    "        # Normalise features\n",
    "        if self.feature_norm:\n",
    "            if self.norm == \"batch\":\n",
    "                x = self.feature_norm(x)\n",
    "            elif self.norm == \"instance\":\n",
    "                x = self.feature_norm(x, batch)\n",
    "            x = self.feature_norm(x, batch)\n",
    "        return x\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr, additional_message_features):\n",
    "        \"\"\"Create messages\"\"\"\n",
    "        if additional_message_features is None:\n",
    "            input = torch.cat((x_i, x_j), dim=-1)\n",
    "        else:\n",
    "            input = torch.cat((x_i, x_j, additional_message_features), dim=-1)\n",
    "\n",
    "        message = self.message_layer_1(input, edge_attr)\n",
    "        message = self.message_layer_2(message, edge_attr)\n",
    "\n",
    "        if self.message_norm:\n",
    "            message = self.message_norm(message)\n",
    "        return message\n",
    "\n",
    "    def update(self, message, x, node_attr):\n",
    "        \"\"\"Update note features\"\"\"\n",
    "        input = torch.cat((x, message), dim=-1)\n",
    "        update = self.update_layer_1(input, node_attr)\n",
    "        update = self.update_layer_2(update, node_attr)\n",
    "        x += update  # Residual connection\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steerable modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__init__` method initializes the neural network's architecture, which consists of an embedding layer, several message passing layers, and output layers. The `forward` method performs the forward pass of the neural network on a graph object.\n",
    "\n",
    "During the forward pass, the graph object's features are first embedded using the `embedding_layer`. The resulting node features are then passed through the layers, which perform message passing between nodes. The output from the message passing layers is then processed by the `pre_pool1` and `pre_pool2` layers to prepare it for pooling.\n",
    "\n",
    "The pooling method is determined by the pool argument passed to the SEGNN constructor. Currently, the module supports average and sum pooling. If the output task is graph-level, the pooled output is passed through the `post_pool1` and `post_pool2` layers to produce the final output. If the output task is node-level, the pooled output is passed through the `pre_pool2` layer to produce the final output.\n",
    "\n",
    "The `catch_isolated_nodes` method is used to handle isolated nodes in the input graph, which should still receive node attributes. If the input graph contains isolated nodes, new attributes are added to the graph object to ensure that every node has an attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEGNN(nn.Module):\n",
    "    \"\"\"Steerable E(3) equivariant message passing network\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_irreps,\n",
    "        hidden_irreps,\n",
    "        output_irreps,\n",
    "        edge_attr_irreps,\n",
    "        node_attr_irreps,\n",
    "        num_layers,\n",
    "        norm=None,\n",
    "        pool=\"avg\",\n",
    "        task=\"graph\",\n",
    "        additional_message_irreps=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.task = task\n",
    "        # Create network, embedding first\n",
    "        # self.embedding_layer_1 = O3TensorProductSwishGate(\n",
    "        #     input_irreps, hidden_irreps, node_attr_irreps\n",
    "        # )\n",
    "        # self.embedding_layer_2 = O3TensorProduct(\n",
    "        #     hidden_irreps, hidden_irreps, node_attr_irreps\n",
    "        # )\n",
    "\n",
    "        self.embedding_layer = O3TensorProduct(\n",
    "            input_irreps, hidden_irreps, node_attr_irreps\n",
    "        )\n",
    "\n",
    "        # Message passing layers.\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(\n",
    "                SEGNNLayer(\n",
    "                    hidden_irreps,\n",
    "                    hidden_irreps,\n",
    "                    hidden_irreps,\n",
    "                    edge_attr_irreps,\n",
    "                    node_attr_irreps,\n",
    "                    norm=norm,\n",
    "                    additional_message_irreps=additional_message_irreps,\n",
    "                )\n",
    "            )\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        # Prepare for output irreps, since the attrs will disappear after pooling\n",
    "        if task == \"graph\":\n",
    "            pooled_irreps = (\n",
    "                (output_irreps * hidden_irreps.num_irreps).simplify().sort().irreps\n",
    "            )\n",
    "            self.pre_pool1 = O3TensorProductSwishGate(\n",
    "                hidden_irreps, hidden_irreps, node_attr_irreps\n",
    "            )\n",
    "            self.pre_pool2 = O3TensorProduct(\n",
    "                hidden_irreps, pooled_irreps, node_attr_irreps\n",
    "            )\n",
    "            self.post_pool1 = O3TensorProductSwishGate(pooled_irreps, pooled_irreps)\n",
    "            self.post_pool2 = O3TensorProduct(pooled_irreps, output_irreps)\n",
    "            self.init_pooler(pool)\n",
    "        elif task == \"node\":\n",
    "            self.pre_pool1 = O3TensorProductSwishGate(\n",
    "                hidden_irreps, hidden_irreps, node_attr_irreps\n",
    "            )\n",
    "            self.pre_pool2 = O3TensorProduct(\n",
    "                hidden_irreps, output_irreps, node_attr_irreps\n",
    "            )\n",
    "\n",
    "    def init_pooler(self, pool):\n",
    "        \"\"\"Initialise pooling mechanism\"\"\"\n",
    "        if pool == \"avg\":\n",
    "            self.pooler = global_mean_pool\n",
    "        elif pool == \"sum\":\n",
    "            self.pooler = global_add_pool\n",
    "\n",
    "    def catch_isolated_nodes(self, graph):\n",
    "        \"\"\"Isolated nodes should also obtain attributes\"\"\"\n",
    "        if (\n",
    "            graph.contains_isolated_nodes()\n",
    "            and graph.edge_index.max().item() + 1 != graph.num_nodes\n",
    "        ):\n",
    "            nr_add_attr = graph.num_nodes - (graph.edge_index.max().item() + 1)\n",
    "            add_attr = graph.node_attr.new_tensor(\n",
    "                np.zeros((nr_add_attr, node_attr.shape[-1]))\n",
    "            )\n",
    "            graph.node_attr = torch.cat((graph.node_attr, add_attr), -2)\n",
    "        # Trivial irrep value should always be 1 (is automatically so for connected nodes, but isolated nodes are now 0)\n",
    "        graph.node_attr[:, 0] = 1.0\n",
    "\n",
    "    def forward(self, graph):\n",
    "        \"\"\"SEGNN forward pass\"\"\"\n",
    "        x, pos, edge_index, edge_attr, node_attr, batch = (\n",
    "            graph.x,\n",
    "            graph.pos,\n",
    "            graph.edge_index,\n",
    "            graph.edge_attr,\n",
    "            graph.node_attr,\n",
    "            graph.batch,\n",
    "        )\n",
    "        try:\n",
    "            additional_message_features = graph.additional_message_features\n",
    "        except AttributeError:\n",
    "            additional_message_features = None\n",
    "\n",
    "        self.catch_isolated_nodes(graph)\n",
    "\n",
    "        # Embed\n",
    "        # x = self.embedding_layer_1(x, node_attr)\n",
    "        # x = self.embedding_layer_2(x, node_attr)\n",
    "        x = self.embedding_layer(x, node_attr)\n",
    "\n",
    "        # Pass messages\n",
    "        # This iteration applies each layer's forward method sequentially to the input tensor x. \n",
    "        for layer in self.layers:\n",
    "            x = layer(\n",
    "                x, edge_index, edge_attr, node_attr, batch, additional_message_features\n",
    "            )\n",
    "\n",
    "        # Pre pool\n",
    "        x = self.pre_pool1(x, node_attr)\n",
    "        x = self.pre_pool2(x, node_attr)\n",
    "\n",
    "        if self.task == \"graph\":\n",
    "            # Pool over nodes\n",
    "            x = self.pooler(x, batch)\n",
    "\n",
    "            # Predict\n",
    "            x = self.post_pool1(x)\n",
    "            x = self.post_pool2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SEGNN(input_irreps,\n",
    "              hidden_irreps,\n",
    "              output_irreps,\n",
    "              edge_attr_irreps,\n",
    "              node_attr_irreps,\n",
    "              num_layers=layers,\n",
    "              norm=norm,\n",
    "              pool=pool,\n",
    "              task=task,\n",
    "              additional_message_irreps=additional_message_irreps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.QM9'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = \"_\".join([\"segnn\", str(dataset), target, str(np.random.randint(1e4, 1e5))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'segnn_QM9(100000)_alpha_82006'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEGNN(\n",
      "  (embedding_layer): O3TensorProduct(\n",
      "    (tp): FullyConnectedTensorProduct(5x0e x 1x0e+1x1o+1x2e+1x3o -> 36x0e+36x1o+36x2e | 540 paths | 540 weights)\n",
      "  )\n",
      "  (layers): ModuleList(\n",
      "    (0): SEGNNLayer()\n",
      "    (1): SEGNNLayer()\n",
      "    (2): SEGNNLayer()\n",
      "    (3): SEGNNLayer()\n",
      "    (4): SEGNNLayer()\n",
      "    (5): SEGNNLayer()\n",
      "    (6): SEGNNLayer()\n",
      "  )\n",
      "  (pre_pool1): O3TensorProductSwishGate(\n",
      "    (tp): FullyConnectedTensorProduct(36x0e+36x1o+36x2e x 1x0e+1x1o+1x2e+1x3o -> 108x0e+36x1o+36x2e | 24624 paths | 24624 weights)\n",
      "    (gate): Gate (108x0e+36x1o+36x2e -> 36x0e+36x1o+36x2e)\n",
      "  )\n",
      "  (pre_pool2): O3TensorProduct(\n",
      "    (tp): FullyConnectedTensorProduct(36x0e+36x1o+36x2e x 1x0e+1x1o+1x2e+1x3o -> 108x0e | 11664 paths | 11664 weights)\n",
      "  )\n",
      "  (post_pool1): O3TensorProductSwishGate(\n",
      "    (tp): FullyConnectedTensorProduct(108x0e x 1x0e -> 108x0e | 11664 paths | 11664 weights)\n",
      "    (gate): SiLU()\n",
      "  )\n",
      "  (post_pool2): O3TensorProduct(\n",
      "    (tp): FullyConnectedTensorProduct(108x0e x 1x0e -> 1x0e | 108 paths | 108 weights)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,033,525 parameters.\n"
     ]
    }
   ],
   "source": [
    "print(\"The model has {:,} parameters.\".format(sum(p.numel() for p in model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "from torch.optim.lr_scheduler import MultiStepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define evaluation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here, the `N` tensor will be used to keep track of the total number of samples in the dataloader, and `score` tensor will be used to keep track of the sum of the losses computed for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device, loc=0, scale=1):\n",
    "    \"\"\" Evaluate a model on the dataloader, with distributed communication (if necessary) \"\"\"\n",
    "    model.eval()\n",
    "    N = torch.zeros(1).to(device)\n",
    "    score = torch.zeros(1).to(device)\n",
    "\n",
    "    with torch.no_grad():  #ensure that the computation graph is not built, which saves memory and speeds up the process. \n",
    "        for graph in dataloader:\n",
    "            graph = graph.to(device)\n",
    "            out = model(graph).squeeze()\n",
    "\n",
    "            n = graph.y.size(0)\n",
    "            N += n\n",
    "            score += n*criterion(out*scale + loc, graph.y)\n",
    "\n",
    "    model.train()\n",
    "    # if world_size > 1:\n",
    "    #     dist.all_reduce(score)\n",
    "    #     dist.all_reduce(N)\n",
    "\n",
    "    return (score/N).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def save_model(model, dir, id, gpu=\"\"):\n",
    "    \"\"\" Save a model \"\"\"\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    if gpu != \"\":\n",
    "        gpu = \"_\" + str(gpu)\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(dir, id + gpu + \".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, dir, id, gpu=\"\"):\n",
    "    \"\"\" Load a state dict into a model \"\"\"\n",
    "    if gpu != \"\":\n",
    "        gpu = \"_\" + str(gpu)\n",
    "    state_dict = torch.load(os.path.join(dir, id + gpu + \".pt\"))\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define training function.\n",
    "\n",
    "The function first creates dataloaders for the training, validation, and test sets using the make_dataloader() function. It also calculates the mean and MAD (median absolute deviation) of the target variable in the training set.\n",
    "\n",
    "The optimizer and learning rate scheduler are set up next, followed by the loss function (in this case, L1 loss). The function then initializes the logging and wandb parameters (if logging is enabled) and starts the training loop.\n",
    "\n",
    "For each epoch, the function loops through the training set and trains the model using the optimizer and loss function. The function also logs training statistics and evaluates the model on the validation set after each epoch. The learning rate is adjusted using the scheduler.\n",
    "\n",
    "Finally, the function evaluates the model on the test set and logs the test MAE. If logging is enabled, the function saves the trained model to disk and finishes the logging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_variable=100\n",
    "lr = 5e-4 #learning rate\n",
    "weight_decay=1e-8\n",
    "def train(gpu, model):\n",
    "    \n",
    "    device = 'cuda:' + str(gpu)\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    # Create datasets and dataloaders\n",
    "    # train_loader = utils.make_dataloader(QM9(args.root, args.target, args.radius, \"train\", args.lmax_attr,\n",
    "    #                                          feature_type=args.feature_type), args.batch_size, args.num_workers, args.gpus, gpu)\n",
    "    # valid_loader = utils.make_dataloader(QM9(args.root, args.target, args.radius, \"valid\", args.lmax_attr,\n",
    "    #                                          feature_type=args.feature_type), args.batch_size, args.num_workers, args.gpus, gpu, train=False)\n",
    "    # test_loader = utils.make_dataloader(QM9(args.root, args.target, args.radius, \"test\", args.lmax_attr,\n",
    "    #                                         feature_type=args.feature_type), args.batch_size, args.num_workers, args.gpus, gpu, train=False)\n",
    "\n",
    "    # Get train set statistics\n",
    "    target_mean, target_mad = train_loader.dataset.calc_stats()\n",
    "\n",
    "    # Set up optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[int(0.8*(epochs)), int(0.9*(epochs))], verbose=True)\n",
    "    criterion = nn.L1Loss()\n",
    "\n",
    "    # Logging parameters\n",
    "    # target = args.target\n",
    "    best_valid_MAE = 1e30\n",
    "    i = 0\n",
    "    N_samples = 0\n",
    "    loss_sum = 0\n",
    "    train_MAE_sum = 0\n",
    "\n",
    "    # # Init wandb\n",
    "    # if log and gpu == 0:\n",
    "    #     wandb.init(project=\"SEGNN \" + str(dataset) + \" \" + target, name=ID, entity=\"segnn\")\n",
    "\n",
    "    # Let's start!\n",
    "    # if gpu == 0:\n",
    "    print(\"Training:\", ID)\n",
    "    for epoch in range(epochs):\n",
    "        # # Set epoch so shuffling works right in distributed mode.\n",
    "        # if args.gpus > 1:\n",
    "        #     train_loader.sampler.set_epoch(epoch)\n",
    "        # Training loop\n",
    "\n",
    "        for step, graph in enumerate(train_loader):\n",
    "            # Forward & Backward.\n",
    "            graph = graph.to(device)\n",
    "            out = model(graph).squeeze()\n",
    "            loss = criterion(out, (graph.y - target_mean)/target_mad)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Logging\n",
    "            i += 1\n",
    "            N_samples += graph.y.size(0)\n",
    "            loss_sum += loss\n",
    "            train_MAE_sum += criterion(out.detach()*target_mad + target_mean, graph.y)*graph.y.size(0)\n",
    "\n",
    "            # Report\n",
    "            if i % print_variable == 0:\n",
    "                print(\"epoch:%2d  step:%4d  loss: %0.4f  train MAE:%0.4f\" %\n",
    "                      (epoch, step, loss_sum/i, train_MAE_sum/N_samples))\n",
    "\n",
    "                # if log and gpu == 0:\n",
    "                #     wandb.log({\"loss\": loss_sum/i, target + \" train MAE\": train_MAE_sum /\n",
    "                #                N_samples})\n",
    "\n",
    "                i = 0\n",
    "                N_samples = 0\n",
    "                loss_sum = 0\n",
    "                train_MAE_sum = 0\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        valid_MAE = evaluate(model, valid_loader, criterion, device, target_mean, target_mad)\n",
    "        # Save best validation model\n",
    "        if valid_MAE < best_valid_MAE:\n",
    "            best_valid_MAE = valid_MAE\n",
    "            save_model(model, save_dir, ID, device)\n",
    "        # if gpu == 0:\n",
    "        print(\"VALIDATION: epoch:%2d  step:%4d  %s-MAE:%0.4f\" %\n",
    "                (epoch, step, target, valid_MAE))\n",
    "            # if log:\n",
    "            #     wandb.log({target + \" val MAE\": valid_MAE})\n",
    "\n",
    "        # Adapt learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    model = load_model(model, save_dir, ID, device)\n",
    "    test_MAE = evaluate(model, test_loader, criterion, device, target_mean, target_mad, )\n",
    "    # if gpu == 0:\n",
    "    print(\"TEST: epoch:%2d  step:%4d  %s-MAE:%0.4f\" %\n",
    "            (epoch, step, target, test_MAE))\n",
    "    #     if log:\n",
    "    #         wandb.log({target + \" test MAE\": test_MAE})\n",
    "    #         wandb.save(os.path.join(save_dir, ID + \"_\" + device + \".pt\"))\n",
    "\n",
    "    # if log and gpu == 0:\n",
    "    #     wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on a single gpu...\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Training: segnn_QM9(100000)_alpha_82006\n",
      "epoch: 0  step:  99  loss: 0.6298  train MAE:3.9605\n",
      "epoch: 0  step: 199  loss: 0.4640  train MAE:2.9178\n",
      "epoch: 0  step: 299  loss: 0.4320  train MAE:2.7163\n",
      "epoch: 0  step: 399  loss: 0.3782  train MAE:2.3780\n",
      "epoch: 0  step: 499  loss: 0.3784  train MAE:2.3796\n",
      "epoch: 0  step: 599  loss: 0.3626  train MAE:2.2802\n",
      "epoch: 0  step: 699  loss: 0.3604  train MAE:2.2660\n",
      "VALIDATION: epoch: 0  step: 781  alpha-MAE:2.1186\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "epoch: 1  step:  17  loss: 0.3486  train MAE:2.1932\n",
      "epoch: 1  step: 117  loss: 0.3540  train MAE:2.2259\n",
      "epoch: 1  step: 217  loss: 0.3547  train MAE:2.2303\n",
      "epoch: 1  step: 317  loss: 0.3309  train MAE:2.0808\n",
      "epoch: 1  step: 417  loss: 0.3307  train MAE:2.0797\n",
      "epoch: 1  step: 517  loss: 0.3206  train MAE:2.0162\n",
      "epoch: 1  step: 617  loss: 0.2816  train MAE:1.7710\n",
      "epoch: 1  step: 717  loss: 0.2418  train MAE:1.5207\n",
      "VALIDATION: epoch: 1  step: 781  alpha-MAE:0.8619\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "epoch: 2  step:  35  loss: 0.1735  train MAE:1.0930\n",
      "epoch: 2  step: 135  loss: 0.1499  train MAE:0.9425\n",
      "epoch: 2  step: 235  loss: 0.1133  train MAE:0.7125\n",
      "epoch: 2  step: 335  loss: 0.1581  train MAE:0.9942\n",
      "epoch: 2  step: 435  loss: 0.1073  train MAE:0.6745\n",
      "epoch: 2  step: 535  loss: 0.1334  train MAE:0.8390\n",
      "epoch: 2  step: 635  loss: 0.0985  train MAE:0.6197\n",
      "epoch: 2  step: 735  loss: 0.1187  train MAE:0.7462\n",
      "VALIDATION: epoch: 2  step: 781  alpha-MAE:0.4743\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "epoch: 3  step:  53  loss: 0.0803  train MAE:0.5048\n",
      "epoch: 3  step: 153  loss: 0.0687  train MAE:0.4321\n",
      "epoch: 3  step: 253  loss: 0.0757  train MAE:0.4760\n",
      "epoch: 3  step: 353  loss: 0.1338  train MAE:0.8416\n",
      "epoch: 3  step: 453  loss: 0.1237  train MAE:0.7778\n",
      "epoch: 3  step: 553  loss: 0.1071  train MAE:0.6733\n",
      "epoch: 3  step: 653  loss: 0.0703  train MAE:0.4423\n",
      "epoch: 3  step: 753  loss: 0.0670  train MAE:0.4210\n",
      "VALIDATION: epoch: 3  step: 781  alpha-MAE:0.7060\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "epoch: 4  step:  71  loss: 0.1233  train MAE:0.7756\n",
      "epoch: 4  step: 171  loss: 0.0696  train MAE:0.4376\n",
      "epoch: 4  step: 271  loss: 0.0857  train MAE:0.5387\n",
      "epoch: 4  step: 371  loss: 0.0644  train MAE:0.4048\n",
      "epoch: 4  step: 471  loss: 0.0829  train MAE:0.5214\n",
      "epoch: 4  step: 571  loss: 0.0709  train MAE:0.4460\n",
      "epoch: 4  step: 671  loss: 0.0574  train MAE:0.3612\n",
      "epoch: 4  step: 771  loss: 0.0561  train MAE:0.3527\n",
      "VALIDATION: epoch: 4  step: 781  alpha-MAE:0.7348\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "epoch: 5  step:  89  loss: 0.1098  train MAE:0.6915\n",
      "epoch: 5  step: 189  loss: 0.0520  train MAE:0.3271\n",
      "epoch: 5  step: 289  loss: 0.0519  train MAE:0.3264\n",
      "epoch: 5  step: 389  loss: 0.0504  train MAE:0.3167\n",
      "epoch: 5  step: 489  loss: 0.0592  train MAE:0.3723\n",
      "epoch: 5  step: 589  loss: 0.1231  train MAE:0.7742\n",
      "epoch: 5  step: 689  loss: 0.0851  train MAE:0.5351\n",
      "VALIDATION: epoch: 5  step: 781  alpha-MAE:0.2864\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "epoch: 6  step:   7  loss: 0.0601  train MAE:0.3786\n",
      "epoch: 6  step: 107  loss: 0.0827  train MAE:0.5202\n",
      "epoch: 6  step: 207  loss: 0.0759  train MAE:0.4776\n",
      "epoch: 6  step: 307  loss: 0.1137  train MAE:0.7152\n",
      "epoch: 6  step: 407  loss: 0.0666  train MAE:0.4187\n",
      "epoch: 6  step: 507  loss: 0.0522  train MAE:0.3284\n",
      "epoch: 6  step: 607  loss: 0.0613  train MAE:0.3855\n",
      "epoch: 6  step: 707  loss: 0.0551  train MAE:0.3468\n",
      "VALIDATION: epoch: 6  step: 781  alpha-MAE:0.5739\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "epoch: 7  step:  25  loss: 0.1251  train MAE:0.7865\n",
      "epoch: 7  step: 125  loss: 0.0928  train MAE:0.5836\n",
      "epoch: 7  step: 225  loss: 0.0560  train MAE:0.3522\n",
      "epoch: 7  step: 325  loss: 0.0561  train MAE:0.3531\n",
      "epoch: 7  step: 425  loss: 0.0515  train MAE:0.3238\n",
      "epoch: 7  step: 525  loss: 0.0591  train MAE:0.3715\n",
      "epoch: 7  step: 625  loss: 0.0474  train MAE:0.2978\n",
      "epoch: 7  step: 725  loss: 0.0439  train MAE:0.2763\n"
     ]
    }
   ],
   "source": [
    "print('Starting training on a single gpu...')\n",
    "mode = 'gpu'\n",
    "train(0, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
